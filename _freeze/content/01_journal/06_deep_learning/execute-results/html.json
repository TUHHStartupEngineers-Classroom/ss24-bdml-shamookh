{
  "hash": "1a5f01651c203b9a44edd1bd78fe6a55",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"06 Deep Learning\"\nauthor: \"Muhammad Shamookh\"\ndate: \"2024-06\"\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n    df_print: paged\n    collapsed: false\n    number_sections: true\n    toc_depth: 3\n    code_folding: hide\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(keras)\nlibrary(lime)\nlibrary(rsample)\nlibrary(recipes)\nlibrary(yardstick)\nlibrary(corrr)\nlibrary(reticulate)\nlibrary(tensorflow)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nchurn_data_raw <- read.csv(\"./06_dl_files/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n\nglimpse(churn_data_raw)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Rows: 7,043\n#> Columns: 21\n#> $ customerID       <chr> \"7590-VHVEG\", \"5575-GNVDE\", \"3668-QPYBK\", \"7795-CFOCW…\n#> $ gender           <chr> \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"Female\",…\n#> $ SeniorCitizen    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#> $ Partner          <chr> \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes…\n#> $ Dependents       <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\"…\n#> $ tenure           <int> 1, 34, 2, 45, 2, 8, 22, 10, 28, 62, 13, 16, 58, 49, 2…\n#> $ PhoneService     <chr> \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", …\n#> $ MultipleLines    <chr> \"No phone service\", \"No\", \"No\", \"No phone service\", \"…\n#> $ InternetService  <chr> \"DSL\", \"DSL\", \"DSL\", \"DSL\", \"Fiber optic\", \"Fiber opt…\n#> $ OnlineSecurity   <chr> \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"…\n#> $ OnlineBackup     <chr> \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"N…\n#> $ DeviceProtection <chr> \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"Y…\n#> $ TechSupport      <chr> \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"Yes…\n#> $ StreamingTV      <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"Ye…\n#> $ StreamingMovies  <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes…\n#> $ Contract         <chr> \"Month-to-month\", \"One year\", \"Month-to-month\", \"One …\n#> $ PaperlessBilling <chr> \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", …\n#> $ PaymentMethod    <chr> \"Electronic check\", \"Mailed check\", \"Mailed check\", \"…\n#> $ MonthlyCharges   <dbl> 29.85, 56.95, 53.85, 42.30, 70.70, 99.65, 89.10, 29.7…\n#> $ TotalCharges     <dbl> 29.85, 1889.50, 108.15, 1840.75, 151.65, 820.50, 1949…\n#> $ Churn            <chr> \"No\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"No\", \"Y…\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nchurn_data_tbl <- churn_data_raw %>%\n                  select(Churn, everything(), -customerID) %>%\n                  tidyr::drop_na()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Split test/training sets\nset.seed(100)\ntrain_test_split <- rsample::initial_split(churn_data_tbl, prop =0.8)\ntrain_test_split\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> <Training/Testing/Total>\n#> <5625/1407/7032>\n```\n\n\n:::\n\n```{.r .cell-code}\n## <Analysis/Assess/Total>\n## <5626/1406/7032>\n\n# Retrieve train and test sets\ntrain_tbl <- training(train_test_split)\ntest_tbl  <- testing(train_test_split)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nchurn_data_tbl %>% ggplot(aes(x = tenure)) + \n                     geom_histogram(binwidth = 0.5, fill =  \"#2DC6D6\") +\n                     labs(\n                       title = \"Tenure Counts Without Binning\",\n                       x     = \"tenure (month)\"\n                       )\n```\n\n::: {.cell-output-display}\n![](06_deep_learning_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nchurn_data_tbl %>% ggplot(aes(x = tenure)) + \n  geom_histogram(bins = 6, color = \"white\", fill =  \"black\") +\n  labs(\n    title = \"Tenure Counts With Six Bins\",\n    x     = \"tenure (month)\"\n  )\n```\n\n::: {.cell-output-display}\n![](06_deep_learning_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nchurn_data_tbl %>% ggplot(aes(x = TotalCharges)) + \n                     geom_histogram(bins = 100, fill =  \"blue\") +\n                     labs(\n                       title = \"TotalCharges Histogram, 100 bins\",\n                       x     = \"TotalCharges\"\n                       )\n```\n\n::: {.cell-output-display}\n![](06_deep_learning_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nchurn_data_tbl_mod <- churn_data_tbl %>% \n  mutate(TotalCharges = log10(TotalCharges))\nchurn_data_tbl_mod %>% ggplot(aes(x = TotalCharges)) + \n                     geom_histogram(bins = 100, fill =  \"red\") +\n                     labs(\n                       title = \"TotalCharges Histogram, 100 bins\",\n                       x     = \"TotalCharges\"\n                       )\n```\n\n::: {.cell-output-display}\n![](06_deep_learning_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Determine if log transformation improves correlation \n# between TotalCharges and Churn\n\ntrain_tbl %>%\n    select(Churn, TotalCharges) %>%\n    mutate(\n        Churn = Churn %>% as.factor() %>% as.numeric(),\n        LogTotalCharges = log(TotalCharges)\n        ) %>%\n    correlate() %>%\n    focus(Churn) %>%\n    fashion()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Correlation computed with\n#> • Method: 'pearson'\n#> • Missing treated using: 'pairwise.complete.obs'\n```\n\n\n:::\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"noquote\"],\"align\":[\"right\"]},{\"label\":[\"Churn\"],\"name\":[2],\"type\":[\"noquote\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"TotalCharges\",\"2\":\"-.21\"},{\"1\":\"LogTotalCharges\",\"2\":\"-.25\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nchurn_data_tbl %>% \n        pivot_longer(cols      = c(Contract, InternetService, MultipleLines, PaymentMethod), \n                     names_to  = \"feature\", \n                     values_to = \"category\") %>% \n        ggplot(aes(category)) +\n          geom_bar(fill = \"#2DC6D6\") +\n          facet_wrap(~ feature, scales = \"free\") +\n          labs(\n            title = \"Features with multiple categories: Need to be one-hot encoded\"\n          ) +\n          theme(axis.text.x = element_text(angle = 25, \n                                           hjust = 1))\n```\n\n::: {.cell-output-display}\n![](06_deep_learning_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create recipe\nrec_obj <- recipe(Churn ~ ., data = train_tbl) %>%\n    step_rm(Churn) %>% \n    step_discretize(tenure, options = list(cuts = 6)) %>%\n    step_log(TotalCharges) %>%\n    step_dummy(all_nominal(), -all_outcomes(), one_hot = T) %>%\n    step_center(all_predictors(), -all_outcomes()) %>%\n    step_scale(all_predictors(), -all_outcomes()) %>%\n    prep(data = train_tbl)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nx_train_tbl <- bake( rec_obj , new_data =  train_tbl)\nx_test_tbl  <- bake( rec_obj , new_data =  test_tbl)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ny_train_vec <- ifelse( train_tbl$Churn == \"Yes\", TRUE, FALSE )\ny_test_vec  <- ifelse( test_tbl$Churn  == \"Yes\", TRUE, FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# # Building our Artificial Neural Network\n\n#model_keras <- keras_model_sequential()\n#\n#model_keras %>% \n #   # First hidden layer\n#    layer_dense(\n#       units              = 16, \n#        kernel_initializer = \"uniform\", \n#        activation         = \"relu\",\n#        input_shape        = ncol(x_train_tbl))%>% \n#    # Dropout to prevent overfitting\n#    layer_dropout(rate = 0.1) %>%\n  #  # Second hidden layer\n#    layer_dense(\n#       units              = 16, \n#        kernel_initializer = \"uniform\", \n#        activation         = \"relu\") %>% \n  #  # Dropout to prevent overfitting\n#    layer_dropout(rate = 0.1) %>%\n  #  # Output layer\n#    layer_dense(\n#        units              = 1, \n#        kernel_initializer = \"uniform\", \n#        activation         = \"sigmoid\") %>% \n #   # Compile ANN\n#   compile(\n#        optimizer = 'adam',\n#        loss      = 'binary_crossentropy',\n#        metrics   = c('accuracy')\n#    )\n#model_keras\n```\n:::\n\n\nI have this error, that I shared in attermost. I tried to do the rest of the code but I do not know if they are accurate or not. I commented the code out in order to make it readable.\n\n::: {.cell}\n\n```{.r .cell-code}\n# x_train_mrx = as.matrix(x_train_tbl)\n# \n# ncol(x_train_tbl)\n# \n# fit_keras <- keras::fit(\n#     object = model_keras,\n#     x = x_train_tbl, \n#     y = y_train_vec , \n#     epochs = 35 , \n#     batch_size = 50 ,\n#     validation_split = 0.3 \n#     )\n# \n# fit_keras\n# \n# plot(fit_keras) +\n#  labs(title = \"Deep Learning Training Results\") +\n#   theme(legend.position  = \"bottom\", \n#         strip.placement  = \"inside\",\n#         strip.background = element_rect(fill = \"#grey\"))\n# \n## # Predicted Class\n# yhat_keras_class_vec <- predict_classes(object = model_keras, x = #as.matrix(x_test_tbl)) %>%\n#    as.vector()\n# \n# # Predicted Class Probability\n#as.matrix(x_test_tbl)) %>%\n#     as.vector()\n# \n# # Format test data and predictions for yardstick metrics\n# estimates_keras_tbl <- tibble(\n#     truth      = as.factor(y_test_vec) %>% fct_recode(yes = \"1\", no = #\"0\"),\n#     estimate   = as.factor(yhat_keras_class_vec) %>% fct_recode(yes = #\"1\", no = \"0\"),\n#    class_prob = yhat_keras_prob_vec\n# )\n# \n#estimates_keras_tbl\n# \n# # Confusion Table\n# estimates_keras_tbl %>% conf_mat(\n#   truth,\n#   estimate)\n#\n# # Accuracy\n# estimates_keras_tbl %>% accuracy(truth, estimate)\n# \n# # AUC\n# estimates_keras_tbl %>% roc_auc(\n#   data,\n#   truth,\n#   event_level = \"second\")\n# \n# # Precision\n# tibble(\n#     precision = precision(\n#                         data,\n#                         truth),\n#     recall    = recall(\n#                       data,\n#                       truth)\n# )\n# \n# # F1-Statistic\n# estimates_keras_tbl %>% f_meas(truth, estimate, beta = 1)\n# \n# class(model_keras)\n# \n# # Setup lime::model_type() function for keras\n# model_type.keras.engine.sequential.Sequential  <- function(x, ...) {\n#     return(\"classification\")\n# }\n# \n# # Setup lime::predict_model() function for keras\n# predict_model.keras.engine.sequential.Sequential <- function(x, newdata, #type, ...) {\n#     pred <- predict_proba(object = x, x = as.matrix(newdata))\n#     return(data.frame(Yes = pred, No = 1 - pred))\n# }\n# \n# library(lime)\n# # Test our predict_model() function\n# predict_model(x = model_keras, newdata = x_test_tbl, type = 'raw') %>%\n#     tibble::as_tibble()\n# \n# # Run lime() on training set\n# explainer <- lime::lime(\n#     x_train_tbl, \n#     y_train_vec , \n#     bin_continuous = FALSE)\n# \n# explanation <- lime::explain(\n#     x_test_tbl[1:10,], \n#     explainer = explainer, \n#     n_labels   = 1, \n#     n_features = 51,\n#     kernel_width   = 1)\n# \n# # Feature correlations to Churn\n# corrr_analysis <- x_train_tbl %>%\n#     mutate(Churn = y_train_vec) %>%\n#     correlate() %>%\n#     focus(Churn) %>%\n#     rename(feature = rowname) %>%\n#     arrange(abs(Churn)) %>%\n#     mutate(feature = as_factor(feature)) \n# corrr_analysis\n# \n# # Correlation visualization\n# corrr_analysis %>%\n#   ggplot(aes(x = ..., y = fct_reorder(..., desc(...)))) +\n#   geom_point() +\n#   \n#   # Positive Correlations - Contribute to churn\n#  geom_segment(aes(xend = ..., yend = ...), \n#               color = \"red\", \n#               data = corrr_analysis %>% filter(... > ...)) +\n#   geom_point(color = \"red\", \n#              data = corrr_analysis %>% filter(... > ...)) +\n#   \n#   # Negative Correlations - Prevent churn\n#  geom_segment(aes(xend = 0, yend = feature), \n#               color = \"#2DC6D6\", \n#                data = ...) +\n#   geom_point(color = \"#2DC6D6\", \n#              data = ...) +\n#   \n#   # Vertical lines\n#   geom_vline(xintercept = 0, color = \"#f1fa8c\", size = 1, linetype = 2) +\n#   geom_vline( ... ) +\n#   geom_vline( ... ) +\n#   \n#   # Aesthetics\n#   labs( ... )\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}