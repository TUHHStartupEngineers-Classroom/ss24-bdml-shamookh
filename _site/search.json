[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#first-test-codefunction",
    "href": "index.html#first-test-codefunction",
    "title": "My Lab Journal",
    "section": "First Test Code/Function",
    "text": "First Test Code/Function\nroll3 &lt;- function(faces = 1:6, number_of_dice = 1) {\ndice &lt;- sample(x = faces, size = number_of_dice,\n             replace = TRUE, \n             \n             \n             prob = c(0.1, 0.1, 0.1, 0.1, 0.1, 0.5))\n             \n             \nsum(dice)\n}"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website everytime before you want to upload changes"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html",
    "href": "content/01_journal/02_data_acquisition.html",
    "title": "02 Supervised ML",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(parsnip)\nlibrary(recipes)\nlibrary(rsample)\nlibrary(yardstick)\nlibrary(rpart.plot)\n\n\nmodel_01_linear_lm_simple &lt;- linear_reg(mode = \"regression\") %&gt;%\n  set_engine(\"lm\")\n\nbike_orderlines_tbl &lt;- readRDS(\"./02_ml_sup_files/bike_orderlines.rds\")\nbike_orderlines_tbl %&gt;%\nglimpse()\n\n#&gt; Rows: 15,644\n#&gt; Columns: 18\n#&gt; $ order_id       &lt;dbl&gt; 1, 1, 2, 2, 3, 3, 3, 3, 3, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7…\n#&gt; $ order_line     &lt;dbl&gt; 1, 2, 1, 2, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1…\n#&gt; $ order_date     &lt;dttm&gt; 2015-01-07, 2015-01-07, 2015-01-10, 2015-01-10, 2015-0…\n#&gt; $ model          &lt;chr&gt; \"Spectral CF 7 WMN\", \"Ultimate CF SLX Disc 8.0 ETAP\", \"…\n#&gt; $ model_year     &lt;dbl&gt; 2021, 2020, 2021, 2019, 2020, 2020, 2020, 2021, 2020, 2…\n#&gt; $ category_1     &lt;chr&gt; \"Mountain\", \"Road\", \"Mountain\", \"Road\", \"Mountain\", \"Hy…\n#&gt; $ category_2     &lt;chr&gt; \"Trail\", \"Race\", \"Trail\", \"Triathlon Bike\", \"Dirt Jump\"…\n#&gt; $ category_3     &lt;chr&gt; \"Spectral\", \"Ultimate\", \"Neuron\", \"Speedmax\", \"Stitched…\n#&gt; $ price          &lt;dbl&gt; 3119, 5359, 2729, 1749, 1219, 1359, 2529, 1559, 3899, 6…\n#&gt; $ quantity       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1…\n#&gt; $ total_price    &lt;dbl&gt; 3119, 5359, 2729, 1749, 1219, 1359, 2529, 1559, 3899, 6…\n#&gt; $ frame_material &lt;chr&gt; \"carbon\", \"carbon\", \"carbon\", \"carbon\", \"aluminium\", \"c…\n#&gt; $ weight         &lt;dbl&gt; 13.80, 7.44, 14.06, 8.80, 11.50, 8.80, 8.20, 8.85, 14.4…\n#&gt; $ url            &lt;chr&gt; \"https://www.canyon.com/en-de/mountain-bikes/trail-bike…\n#&gt; $ bikeshop       &lt;chr&gt; \"AlexandeRad\", \"AlexandeRad\", \"WITT-RAD\", \"WITT-RAD\", \"…\n#&gt; $ location       &lt;chr&gt; \"Hamburg, Hamburg\", \"Hamburg, Hamburg\", \"Bremen, Bremen…\n#&gt; $ lat            &lt;dbl&gt; 53.57532, 53.57532, 53.07379, 53.07379, 48.78234, 48.78…\n#&gt; $ lng            &lt;dbl&gt; 10.015340, 10.015340, 8.826754, 8.826754, 9.180819, 9.1…\n\nbike_features_tbl &lt;- readRDS(\"./02_ml_sup_files/bike_features_tbl.rds\")\n\nbike_features_tbl &lt;- bike_features_tbl %&gt;%\n  select(model:url, `Rear Derailleur`, `Shift Lever`) %&gt;%\n  set_names(str_replace_all(names(.), \" |-\", \"_\"))\n\n\nset.seed(seed = 1113)\nbike_split_obj &lt;- initial_split(bike_features_tbl, strata = category_2)\n\ntrain_tbl &lt;- training(bike_split_obj)\ntest_tbl &lt;- testing(bike_split_obj)\n\nrecipe_obj &lt;- recipe(price ~ ., data = train_tbl) %&gt;%\n  step_rm(url) %&gt;%\n  step_dummy(all_nominal(), one_hot = TRUE)\n\n\n# Define the workflow\nbikes_wflow &lt;- workflow() %&gt;%\n  add_model(model_01_linear_lm_simple) %&gt;%\n  add_recipe(recipe_obj)\n\n# Train the workflow\nbikes_fit &lt;- bikes_wflow %&gt;%\n  fit(data = train_tbl)\n\n\ncalc_metrics &lt;- function(model, new_data = test_tbl) {\n  model %&gt;%\n    predict(new_data = new_data) %&gt;%\n    bind_cols(new_data %&gt;% select(price)) %&gt;%\n    yardstick::metrics(truth = price, estimate = .pred)\n}\n\nbikes_fit %&gt;%\n  calc_metrics()"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html#spotify-api",
    "href": "content/01_journal/02_data_acquisition.html#spotify-api",
    "title": "Data Acquistion",
    "section": "\n2.1 Spotify API",
    "text": "2.1 Spotify API\n\n# Load required libraries\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(tidyverse)\n\n# Replace with your actual OAuth token\ntoken &lt;- 'BQBcTINcgYgaqH7etCs9vm5X2nKxc2zADfqQbwAP2tnmljk7XthJfaaqKDw4rWFN6cspyISpo7JyQiGIvETRqZ-szLLhyOGp--e_gnzER5RthEDfjtNAUedH8Vf0F8YuEKXCE5wXmfzfXnrItCrxzZIR29-pGlbyPBZHrHsJq1LPAEkUemWZ95ABVoCYlGWTd10EqzocX8zAwcIhtWIrvVDHX4-3SRBMjO-O4QiBMF94f42TSPKp068At2-MuZ0c7SMvbWBaeO3g-0Wt8qT4rvSgPyyn'\n\n# Function to make API request\nfetch_web_api &lt;- function(endpoint, method = \"GET\", body = NULL) {\n  url &lt;- paste0(\"https://api.spotify.com/\", endpoint)\n  \n  res &lt;- httr::VERB(\n    method,\n    url,\n    add_headers(Authorization = paste(\"Bearer\", token)),\n    body = body,\n    encode = \"json\"\n  )\n  \n  if (status_code(res) == 200) {\n    return(content(res, as = \"parsed\", type = \"application/json\"))\n  } else {\n    stop(\"API request failed with status code: \", status_code(res))\n  }\n}\n\n# Function to get top tracks\nget_top_tracks &lt;- function() {\n  endpoint &lt;- \"v1/me/top/tracks?time_range=long_term&limit=5\"\n  response &lt;- fetch_web_api(endpoint)\n  return(response$items)\n}\n\n# Get top tracks\ntop_tracks &lt;- get_top_tracks()\n\n# Process and print the data in a readable format\ntrack_info &lt;- top_tracks %&gt;%\n  map_df(~ data.frame(\n    track_name = .x$name,\n    artist_names = paste(map_chr(.x$artists, \"name\"), collapse = \", \"),\n    stringsAsFactors = FALSE\n  ))\n\nprint(track_info)\n\n#&gt;                                     track_name\n#&gt; 1                     Saari Duniya Jalaa Denge\n#&gt; 2                     Ishq - From \"Lost;Found\"\n#&gt; 3 O Bedardeya (From \"Tu Jhoothi Main Makkaar\")\n#&gt; 4     Saari Duniya Jalaa Denge (From \"Animal\")\n#&gt; 5                                  Sufi Medley\n#&gt;                                 artist_names\n#&gt; 1                             Jaani, B Praak\n#&gt; 2              Faheem Abdullah, Rauhan Malik\n#&gt; 3 Pritam, Arijit Singh, Amitabh Bhattacharya\n#&gt; 4                                    B Praak\n#&gt; 5                           Abdullah Qureshi\n\n# Display as a table\nlibrary(knitr)\nkable(track_info, format = \"markdown\")\n\n\n\n\n\n\n\ntrack_name\nartist_names\n\n\n\nSaari Duniya Jalaa Denge\nJaani, B Praak\n\n\nIshq - From “Lost;Found”\nFaheem Abdullah, Rauhan Malik\n\n\nO Bedardeya (From “Tu Jhoothi Main Makkaar”)\nPritam, Arijit Singh, Amitabh Bhattacharya\n\n\nSaari Duniya Jalaa Denge (From “Animal”)\nB Praak\n\n\nSufi Medley\nAbdullah Qureshi\n\n\n\n\n\n1: Top 5 track and singer names."
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html#rosebike",
    "href": "content/01_journal/02_data_acquisition.html#rosebike",
    "title": "Data Acquistion",
    "section": "\n3.1 Rosebike",
    "text": "3.1 Rosebike\n\nlibrary(tidyverse) # Main Package - Loads dplyr, purrr, etc.\nlibrary(rvest)     # HTML Hacking & Web Scraping\n\n#&gt; \n#&gt; Attaching package: 'rvest'\n\n\n#&gt; The following object is masked from 'package:readr':\n#&gt; \n#&gt;     guess_encoding\n\nlibrary(xopen)     # Quickly opening URLs\nlibrary(jsonlite)  # converts JSON files to R objects\n\n#&gt; \n#&gt; Attaching package: 'jsonlite'\n\n\n#&gt; The following object is masked from 'package:purrr':\n#&gt; \n#&gt;     flatten\n\nlibrary(glue)      # concatenate strings\nlibrary(stringi)   # character string/text processing\nlibrary(purrr)\n\nextract_price &lt;- function(text) {\n  price_str &lt;- str_extract(text, \"[0-9]*,*[0-9]*\\\\.[0-9]*\")\n  price_str &lt;- gsub(\",\", \"\", as.character(price_str))\n  return(price_str)\n}\n\nmake_url &lt;- function(my_string){\n  base_url &lt;- \"https://www.rosebikes.com\"\n  glue(\"{base_url}{my_string}\")\n}\n\n#all model names have numbers in them\nfilter_model_names &lt;- function(model_name) {\n  condition1 &lt;- str_detect(model_name, \"[0-9]\")\n  condition2 &lt;- str_detect(model_name, \"SOUL FIRE\")\n  if (condition1 | condition2) {\n    return(model_name)\n  }\n  return(NULL)\n}\n\nextract_models &lt;- function(model_url) {\n  \n  css_class_model_name &lt;- \".basic-headline__title\"\n  # This part extracts the model names\n  html_model_names &lt;- read_html(model_url) %&gt;%\n    html_nodes(css = css_class_model_name) %&gt;%\n    map(html_text) %&gt;%\n    map(filter_model_names)\n  model_names &lt;- unique(unlist(html_model_names))\n  \n  \n  #This parts extracts the model price\n  css_class_model_price = \".catalog-category-model__price-current-value\"\n  model_prices &lt;- read_html(model_url) %&gt;%\n    html_nodes(css = css_class_model_price) %&gt;%\n    map(html_text) %&gt;%\n    map(extract_price)\n  \n  #The last prices are the prices of the models\n  while (length(model_prices) &gt; length(model_names)) {\n    model_prices[1] &lt;- NULL\n  }\n  model_prices &lt;- model_prices %&gt;%\n    unlist() %&gt;%\n    as.double()\n  \n  models_tbl &lt;- tibble(model_names, model_prices)\n  \n}\n\n\nextract_models_from_category_list_mtb &lt;- function(bike_url){\n  \n  bike_price_xml_path = \"catalog-category-bikes__price-title\"\n  category &lt;- str_extract(bike_url, \"(?&lt;=/)[a-z]*$\")\n  css_class &lt;- \".catalog-category-bikes__button\"\n  \n  html_bike &lt;- read_html(bike_url)\n  \n  html_models_urls &lt;- html_bike %&gt;%\n    html_nodes(css = css_class) %&gt;%\n    html_attr(\"href\") %&gt;%\n    map(make_url)\n  \n  models_in_category_list &lt;- map(html_models_urls, extract_models)\n  models_in_category_list\n  models_in_category_tbl &lt;- models_in_category_list[[1]]\n  for (i in 2:length(models_in_category_list)) {\n    models_in_category_tbl &lt;- add_row(models_in_category_tbl, \n                                      model_names = models_in_category_list[[i]]$model_names,\n                                      model_prices = models_in_category_list[[i]]$model_prices)\n  }\n  \n  category = rep(category, times = length(models_in_category_tbl$model_names))\n  models_in_category_tbl$category &lt;- category\n  return(models_in_category_tbl)\n}\n\n\n\nhome_url &lt;- \"https://www.rosebikes.com/bikes\"\n\nhtml_home &lt;- read_html(home_url)\nhtml_categories_urls &lt;- html_home %&gt;%\n  html_nodes(css = \".catalog-navigation__link\") %&gt;%\n  html_attr(\"href\") %&gt;%\n  map(make_url)\n\n\ntbl &lt;- html_categories_urls[[1]] %&gt;%\n  extract_models_from_category_list_mtb\n\n#&gt; Warning: Unknown or uninitialised column: `model_names`.\n#&gt; Unknown or uninitialised column: `model_names`.\n\ntbl \n\n\n\n  \n\n\n\nTable 2: Model names and Model prices (Prices are in Euro)"
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html",
    "href": "content/01_journal/04_data_visualization.html",
    "title": "Performance Measures",
    "section": "",
    "text": "library(tidyverse)\nlibrary(GGally)\nlibrary(h2o)\nlibrary(recipes)\nlibrary(rsample)\n\n\nproduct_backorders_tbl &lt;- read_csv(\"./04_perf_meas_files/product_backorders.txt\")\n\n#&gt; Rows: 19053 Columns: 23\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr  (7): potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_bu...\n#&gt; dbl (16): sku, national_inv, lead_time, in_transit_qty, forecast_3_month, fo...\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(product_backorders_tbl)\n\n#&gt; Rows: 19,053\n#&gt; Columns: 23\n#&gt; $ sku               &lt;dbl&gt; 1113121, 1113268, 1113874, 1114222, 1114823, 1115453…\n#&gt; $ national_inv      &lt;dbl&gt; 0, 0, 20, 0, 0, 55, -34, 4, 2, -7, 1, 2, 0, 0, 0, 0,…\n#&gt; $ lead_time         &lt;dbl&gt; 8, 8, 2, 8, 12, 8, 8, 9, 8, 8, 8, 8, 12, 2, 12, 4, 2…\n#&gt; $ in_transit_qty    &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0…\n#&gt; $ forecast_3_month  &lt;dbl&gt; 6, 2, 45, 9, 31, 216, 120, 43, 4, 56, 2, 5, 5, 54, 4…\n#&gt; $ forecast_6_month  &lt;dbl&gt; 6, 3, 99, 14, 31, 360, 240, 67, 6, 96, 4, 9, 6, 72, …\n#&gt; $ forecast_9_month  &lt;dbl&gt; 6, 4, 153, 21, 31, 492, 240, 115, 9, 112, 6, 13, 9, …\n#&gt; $ sales_1_month     &lt;dbl&gt; 0, 1, 16, 5, 7, 30, 83, 5, 1, 13, 0, 1, 0, 0, 1, 0, …\n#&gt; $ sales_3_month     &lt;dbl&gt; 4, 2, 42, 17, 15, 108, 122, 22, 5, 30, 2, 5, 4, 0, 3…\n#&gt; $ sales_6_month     &lt;dbl&gt; 9, 3, 80, 36, 33, 275, 144, 40, 6, 56, 3, 8, 5, 0, 4…\n#&gt; $ sales_9_month     &lt;dbl&gt; 12, 3, 111, 43, 47, 340, 165, 58, 9, 76, 4, 11, 6, 0…\n#&gt; $ min_bank          &lt;dbl&gt; 0, 0, 10, 0, 2, 51, 33, 4, 2, 0, 0, 0, 3, 4, 0, 0, 0…\n#&gt; $ potential_issue   &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n#&gt; $ pieces_past_due   &lt;dbl&gt; 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#&gt; $ perf_6_month_avg  &lt;dbl&gt; 0.90, 0.96, 0.81, 0.96, 0.98, 0.00, 1.00, 0.69, 1.00…\n#&gt; $ perf_12_month_avg &lt;dbl&gt; 0.89, 0.97, 0.88, 0.98, 0.98, 0.00, 0.97, 0.68, 0.95…\n#&gt; $ local_bo_qty      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 34, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, …\n#&gt; $ deck_risk         &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n#&gt; $ oe_constraint     &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n#&gt; $ ppap_risk         &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No…\n#&gt; $ stop_auto_buy     &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n#&gt; $ rev_stop          &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n#&gt; $ went_on_backorder &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n\n\n\nrecipe_obj &lt;- recipe(went_on_backorder ~ ., data = product_backorders_tbl) %&gt;%\n  step_zv(all_predictors()) %&gt;%\n  step_mutate_at(potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_buy, rev_stop, fn = as.factor) %&gt;%\n  prep()\n\n\nset.seed(1234)\n\nsplit_obj &lt;- initial_split(product_backorders_tbl, prop = 0.85)\ntrain_readable_tbl &lt;- training(split_obj)\ntest_readable_tbl &lt;- testing(split_obj)\n\ntrain_tbl &lt;- bake(recipe_obj, new_data = train_readable_tbl)\ntest_tbl  &lt;- bake(recipe_obj, new_data = test_readable_tbl)\n\n\nh2o.init()\n\n#&gt;  Connection successful!\n#&gt; \n#&gt; R is connected to the H2O cluster: \n#&gt;     H2O cluster uptime:         12 minutes 32 seconds \n#&gt;     H2O cluster timezone:       Asia/Karachi \n#&gt;     H2O data parsing timezone:  UTC \n#&gt;     H2O cluster version:        3.36.0.4 \n#&gt;     H2O cluster version age:    2 years, 2 months and 24 days !!! \n#&gt;     H2O cluster name:           H2O_started_from_R_Crown_Tech_pgz902 \n#&gt;     H2O cluster total nodes:    1 \n#&gt;     H2O cluster total memory:   3.53 GB \n#&gt;     H2O cluster total cores:    8 \n#&gt;     H2O cluster allowed cores:  8 \n#&gt;     H2O cluster healthy:        TRUE \n#&gt;     H2O Connection ip:          localhost \n#&gt;     H2O Connection port:        54321 \n#&gt;     H2O Connection proxy:       NA \n#&gt;     H2O Internal Security:      FALSE \n#&gt;     R Version:                  R version 4.4.1 (2024-06-14 ucrt)\n\n\n#&gt; Warning in h2o.clusterInfo(): \n#&gt; Your H2O cluster version is too old (2 years, 2 months and 24 days)!\n#&gt; Please download and install the latest version from http://h2o.ai/download/\n\nsplit_h2o &lt;- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)\n\n#&gt; \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\ntrain_h2o &lt;- split_h2o[[1]]\nvalid_h2o &lt;- split_h2o[[2]]\ntest_h2o  &lt;- as.h2o(test_tbl)\n\n#&gt; \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\ny &lt;- \"went_on_backorder\"\nx &lt;- setdiff(names(train_h2o), y)\n\n\nautoml_models_h2o &lt;- h2o.automl(\n  x = x,\n  y = y,\n  training_frame    = train_h2o,\n  validation_frame  = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs  = 120,\n  nfolds            = 5 \n)\n\n#&gt; \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |                                                                      |   1%\n#&gt; 22:28:15.897: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n#&gt; 22:28:15.900: AutoML: XGBoost is not available; skipping it.\n#&gt; 22:28:15.902: Step 'best_of_family_xgboost' not defined in provider 'StackedEnsemble': skipping it.\n#&gt; 22:28:15.902: Step 'all_xgboost' not defined in provider 'StackedEnsemble': skipping it.\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |=====================                                                 |  29%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  38%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |====================================                                  |  51%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  71%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |=====================================================                 |  75%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |============================================================          |  85%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |================================================================      |  91%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |===================================================================   |  95%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |======================================================================| 100%\n\n\n\ntypeof(automl_models_h2o)\n\n#&gt; [1] \"S4\"\n\nslotNames(automl_models_h2o)\n\n#&gt; [1] \"project_name\"   \"leader\"         \"leaderboard\"    \"event_log\"     \n#&gt; [5] \"modeling_steps\" \"training_info\"\n\nautoml_models_h2o@leaderboard\n\n#&gt;                                                  model_id       auc   logloss\n#&gt; 1    StackedEnsemble_AllModels_2_AutoML_3_20240623_222815 0.9528473 0.1742689\n#&gt; 2    StackedEnsemble_AllModels_1_AutoML_3_20240623_222815 0.9527280 0.1757474\n#&gt; 3 StackedEnsemble_BestOfFamily_3_AutoML_3_20240623_222815 0.9508354 0.1771444\n#&gt; 4 StackedEnsemble_BestOfFamily_2_AutoML_3_20240623_222815 0.9501388 0.1792685\n#&gt; 5                          GBM_4_AutoML_3_20240623_222815 0.9495915 0.1818160\n#&gt; 6 StackedEnsemble_BestOfFamily_1_AutoML_3_20240623_222815 0.9494060 0.1799105\n#&gt;       aucpr mean_per_class_error      rmse        mse\n#&gt; 1 0.7566698            0.1495575 0.2299987 0.05289938\n#&gt; 2 0.7531899            0.1363528 0.2308837 0.05330729\n#&gt; 3 0.7442111            0.1444714 0.2314254 0.05355771\n#&gt; 4 0.7390554            0.1383872 0.2325584 0.05408340\n#&gt; 5 0.7333920            0.1361340 0.2343808 0.05493437\n#&gt; 6 0.7430157            0.1398037 0.2340836 0.05479513\n#&gt; \n#&gt; [14 rows x 7 columns]\n\nautoml_models_h2o@leader\n\n#&gt; Model Details:\n#&gt; ==============\n#&gt; \n#&gt; H2OBinomialModel: stackedensemble\n#&gt; Model ID:  StackedEnsemble_AllModels_2_AutoML_3_20240623_222815 \n#&gt; Number of Base Models: 9\n#&gt; \n#&gt; Base Models (count by algorithm type):\n#&gt; \n#&gt; deeplearning          drf          gbm          glm \n#&gt;            1            2            5            1 \n#&gt; \n#&gt; Metalearner:\n#&gt; \n#&gt; Metalearner algorithm: glm\n#&gt; Metalearner cross-validation fold assignment:\n#&gt;   Fold assignment scheme: AUTO\n#&gt;   Number of folds: 5\n#&gt;   Fold column: NULL\n#&gt; Metalearner hyperparameters: \n#&gt; \n#&gt; \n#&gt; H2OBinomialMetrics: stackedensemble\n#&gt; ** Reported on training data. **\n#&gt; \n#&gt; MSE:  0.0262093\n#&gt; RMSE:  0.1618929\n#&gt; LogLoss:  0.09774234\n#&gt; Mean Per-Class Error:  0.08191296\n#&gt; AUC:  0.9888977\n#&gt; AUCPR:  0.9397221\n#&gt; Gini:  0.9777953\n#&gt; \n#&gt; Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#&gt;          No  Yes    Error       Rate\n#&gt; No     8618  140 0.015985  =140/8758\n#&gt; Yes     178 1026 0.147841  =178/1204\n#&gt; Totals 8796 1166 0.031921  =318/9962\n#&gt; \n#&gt; Maximum Metrics: Maximum metrics at their respective thresholds\n#&gt;                         metric threshold       value idx\n#&gt; 1                       max f1  0.442038    0.865823 166\n#&gt; 2                       max f2  0.263113    0.891497 221\n#&gt; 3                 max f0point5  0.603386    0.899763 125\n#&gt; 4                 max accuracy  0.498424    0.968480 152\n#&gt; 5                max precision  0.992235    1.000000   0\n#&gt; 6                   max recall  0.026407    1.000000 343\n#&gt; 7              max specificity  0.992235    1.000000   0\n#&gt; 8             max absolute_mcc  0.442038    0.847853 166\n#&gt; 9   max min_per_class_accuracy  0.212188    0.943522 239\n#&gt; 10 max mean_per_class_accuracy  0.263113    0.945996 221\n#&gt; 11                     max tns  0.992235 8758.000000   0\n#&gt; 12                     max fns  0.992235 1202.000000   0\n#&gt; 13                     max fps  0.000150 8758.000000 399\n#&gt; 14                     max tps  0.026407 1204.000000 343\n#&gt; 15                     max tnr  0.992235    1.000000   0\n#&gt; 16                     max fnr  0.992235    0.998339   0\n#&gt; 17                     max fpr  0.000150    1.000000 399\n#&gt; 18                     max tpr  0.026407    1.000000 343\n#&gt; \n#&gt; Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`\n#&gt; H2OBinomialMetrics: stackedensemble\n#&gt; ** Reported on validation data. **\n#&gt; \n#&gt; MSE:  0.04479636\n#&gt; RMSE:  0.2116515\n#&gt; LogLoss:  0.1501092\n#&gt; Mean Per-Class Error:  0.1401232\n#&gt; AUC:  0.960825\n#&gt; AUCPR:  0.775796\n#&gt; Gini:  0.9216501\n#&gt; \n#&gt; Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#&gt;          No Yes    Error       Rate\n#&gt; No     2042  87 0.040864   =87/2129\n#&gt; Yes      62 197 0.239382    =62/259\n#&gt; Totals 2104 284 0.062395  =149/2388\n#&gt; \n#&gt; Maximum Metrics: Maximum metrics at their respective thresholds\n#&gt;                         metric threshold       value idx\n#&gt; 1                       max f1  0.386767    0.725599 161\n#&gt; 2                       max f2  0.164770    0.794679 234\n#&gt; 3                 max f0point5  0.601508    0.747801 107\n#&gt; 4                 max accuracy  0.601508    0.939698 107\n#&gt; 5                max precision  0.972451    1.000000   0\n#&gt; 6                   max recall  0.012311    1.000000 363\n#&gt; 7              max specificity  0.972451    1.000000   0\n#&gt; 8             max absolute_mcc  0.386767    0.691416 161\n#&gt; 9   max min_per_class_accuracy  0.158203    0.902771 238\n#&gt; 10 max mean_per_class_accuracy  0.164770    0.903541 234\n#&gt; 11                     max tns  0.972451 2129.000000   0\n#&gt; 12                     max fns  0.972451  258.000000   0\n#&gt; 13                     max fps  0.000056 2129.000000 399\n#&gt; 14                     max tps  0.012311  259.000000 363\n#&gt; 15                     max tnr  0.972451    1.000000   0\n#&gt; 16                     max fnr  0.972451    0.996139   0\n#&gt; 17                     max fpr  0.000056    1.000000 399\n#&gt; 18                     max tpr  0.012311    1.000000 363\n#&gt; \n#&gt; Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`\n#&gt; H2OBinomialMetrics: stackedensemble\n#&gt; ** Reported on cross-validation data. **\n#&gt; ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n#&gt; \n#&gt; MSE:  0.05091892\n#&gt; RMSE:  0.2256522\n#&gt; LogLoss:  0.1717777\n#&gt; Mean Per-Class Error:  0.1526662\n#&gt; AUC:  0.9502735\n#&gt; AUCPR:  0.7493797\n#&gt; Gini:  0.900547\n#&gt; \n#&gt; Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#&gt;           No  Yes    Error         Rate\n#&gt; No     11543  610 0.050193   =610/12153\n#&gt; Yes      422 1232 0.255139    =422/1654\n#&gt; Totals 11965 1842 0.074745  =1032/13807\n#&gt; \n#&gt; Maximum Metrics: Maximum metrics at their respective thresholds\n#&gt;                         metric threshold        value idx\n#&gt; 1                       max f1  0.331908     0.704805 208\n#&gt; 2                       max f2  0.111599     0.773585 292\n#&gt; 3                 max f0point5  0.520605     0.733964 146\n#&gt; 4                 max accuracy  0.520605     0.932498 146\n#&gt; 5                max precision  0.989240     1.000000   0\n#&gt; 6                   max recall  0.002941     1.000000 392\n#&gt; 7              max specificity  0.989240     1.000000   0\n#&gt; 8             max absolute_mcc  0.401400     0.664022 184\n#&gt; 9   max min_per_class_accuracy  0.117577     0.883918 289\n#&gt; 10 max mean_per_class_accuracy  0.111599     0.886617 292\n#&gt; 11                     max tns  0.989240 12153.000000   0\n#&gt; 12                     max fns  0.989240  1651.000000   0\n#&gt; 13                     max fps  0.000088 12153.000000 399\n#&gt; 14                     max tps  0.002941  1654.000000 392\n#&gt; 15                     max tnr  0.989240     1.000000   0\n#&gt; 16                     max fnr  0.989240     0.998186   0\n#&gt; 17                     max fpr  0.000088     1.000000 399\n#&gt; 18                     max tpr  0.002941     1.000000 392\n#&gt; \n#&gt; Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`\n\ntypeof(automl_models_h2o@leader)\n\n#&gt; [1] \"S4\"\n\n\n\npredictions &lt;- h2o.predict(automl_models_h2o@leader, newdata = as.h2o(test_tbl))\n\n#&gt; \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n#&gt; \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\npredictions_tbl &lt;- \n  predictions %&gt;% \n    as_tibble()\n#h2o.saveModel(automl_models_h2o@leader, path = \"./04_perf_meas_files/\")\n\n\npredictions_tbl %&gt;%\n  glimpse()\n\n#&gt; Rows: 2,858\n#&gt; Columns: 3\n#&gt; $ predict &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Yes, No, …\n#&gt; $ No      &lt;dbl&gt; 0.35099977, 0.49446699, 0.10396982, 0.15413307, 0.06619593, 0.…\n#&gt; $ Yes     &lt;dbl&gt; 0.64900023, 0.50553301, 0.89603018, 0.84586693, 0.93380407, 0.…\n\n\n\nautoml_models_h2o@leaderboard %&gt;% \n              as_tibble() %&gt;% \n              select(-c(mean_per_class_error, rmse, mse))\n\n\n  \n\n\n\n\nplot_h2o_leaderboard &lt;- function(h2o_leaderboard, order_by = c(\"auc\", \"logloss\"), \n                                 n_max = 20, size = 4, include_lbl = TRUE) {\n\n    # Setup inputs\n    # adjust input so that all formats are working\n    order_by &lt;- tolower(order_by[[1]])\n\n    leaderboard_tbl &lt;- h2o_leaderboard %&gt;%\n        as_tibble() %&gt;%\n        select(-c(aucpr, mean_per_class_error, rmse, mse)) %&gt;% \n        mutate(model_type = str_extract(model_id, \"[^_]+\")) %&gt;%\n        rownames_to_column(var = \"rowname\") %&gt;%\n        mutate(model_id = paste0(rowname, \". \", model_id) %&gt;% as.factor())\n\n    # Transformation\n    if (order_by == \"auc\") {\n\n        data_transformed_tbl &lt;- leaderboard_tbl %&gt;%\n            slice(1:n_max) %&gt;%\n            mutate(\n                model_id   = as_factor(model_id) %&gt;% reorder(auc),\n                model_type = as.factor(model_type)\n            ) %&gt;%\n                pivot_longer(cols = -c(model_id, model_type, rowname), \n                       names_to = \"key\", \n                       values_to = \"value\", \n                       names_transform = list(key = forcats::fct_inorder)\n                       )\n\n    } else if (order_by == \"logloss\") {\n\n        data_transformed_tbl &lt;- leaderboard_tbl %&gt;%\n            slice(1:n_max) %&gt;%\n            mutate(\n                model_id   = as_factor(model_id) %&gt;% reorder(logloss) %&gt;% fct_rev(),\n                model_type = as.factor(model_type)\n            ) %&gt;%\n            pivot_longer(cols = -c(model_id, model_type, rowname), \n                       names_to = \"key\", \n                       values_to = \"value\", \n                       names_transform = list(key = forcats::fct_inorder)\n                       )\n\n    } else {\n        # If nothing is supplied\n        stop(paste0(\"order_by = '\", order_by, \"' is not a permitted option.\"))\n    }\n\n    # Visualization\n    g &lt;- data_transformed_tbl %&gt;%\n        ggplot(aes(value, model_id, color = model_type)) +\n        geom_point(size = size) +\n        facet_wrap(~ key, scales = \"free_x\") +\n        labs(title = \"Leaderboard Metrics\",\n             subtitle = paste0(\"Ordered by: \", toupper(order_by)),\n             y = \"Model Postion, Model ID\", x = \"\")\n\n    if (include_lbl) g &lt;- g + geom_label(aes(label = round(value, 2), \n                                             hjust = \"inward\"))\n\n    return(g)\n\n}\n\n\n#automl_models_h2o@leaderboard %&gt;% plot_h2o_leaderboard()\n\n\nknitr::include_graphics(\"./04_perf_meas_files/figure-html/unnamed-chunk-12-1.png\")\n\n\n\n\n\n\n\n\nFor some reason I can not build the page because the program have some problem with an h2o function. So I saved the results and loaded them. The used code is commented out.\n\n#h2o.init()\n#deeplearning_h2o &lt;- \n#    h2o.loadModel(\"./04_Modeling/h20_models/DeepLearning_1_AutoML_3_20220614_234925\")\n#deeplearning_h2o@allparameters\n\n# Deeplearning_grid_01 &lt;- h2o.grid(\n# \n#     # See help page for available algos\n#     algorithm = \"deeplearning\",\n#     \n#     # I just use the same as the object\n#     grid_id = \"Deaplearning_grid_01\",\n#     \n#     # The following is for ?h2o.deeplearning()\n#     # predictor and response variables\n#     x = x,\n#     y = y,\n#     \n#     # training and validation frame and crossfold validation\n#     training_frame   = train_h2o,\n#     validation_frame = valid_h2o,\n#     nfolds = 5,\n#     \n#     # Hyperparamters: Use deeplearning_h2o@allparameters to see all\n#     hyper_params = list(\n#         # Use some combinations (the first one was the original)\n#         hidden = list(c(10, 10, 10), c(50, 20, 10), c(20, 20, 20)),\n#         epochs = c(10, 50, 100)\n#     )\n# )\n\n\n# &lt;- h2o.getModel(\"Deaplearning_grid_01_model_3\")\n#Deeplearning_grid_01_model_3 %&gt;%h2o.saveModel(path = \"04_Modeling/Deaplearning_grid_01_model_3\")\n#Deeplearning_grid_01_model_3 &lt;- h2o.loadModel(\"04_Modeling/Deaplearning_grid_01_model_3/Deaplearning_grid_01_model_3\")\n# performance_h2o &lt;- h2o.performance(Deeplearning_grid_01_model_3, newdata = as.h2o(test_tbl))\n# \n# performance_tbl &lt;- performance_h2o %&gt;%\n#     h2o.metric() %&gt;%\n#     as.tibble()\n# \n# theme_new &lt;- theme(\n#       legend.position  = \"bottom\",\n#       panel.background = element_rect(fill   = \"transparent\"),\n#       panel.border     = element_rect(color = \"black\", fill = NA, size = 0.5),\n#       panel.grid.major = element_line(color = \"grey\", size = 0.333)\n#       ) \n# saveRDS(performance_tbl, file = \"performance_tbl.rds\")\n\nperformance_tbl &lt;- readRDS(\"performance_tbl.rds\")\n\n\n#performance_tbl %&gt;%\n#    filter(f1 == max(f1))\n#\n#performance_tbl %&gt;%\n#    ggplot(aes(x = threshold)) +\n#    geom_line(aes(y = precision), color = \"blue\", size = 1) +\n#    geom_line(aes(y = recall), color = \"red\", size = 1) +\n#    \n#    # Insert line where precision and recall are harmonically optimized\n#    geom_vline(xintercept = #h2o.find_threshold_by_max_metric(performance_h2o, \"f1\")) +\n#    labs(title = \"Precision vs Recall\", y = \"value\") +\n#    theme_new\n#\nknitr::include_graphics(\"./04_perf_meas_files/figure-html/unnamed-chunk-15-1.png\")\n\n\n\n\n\n\n\n\n\n#p1 &lt;- performance_tbl %&gt;%\n#  ggplot(aes(fpr, tpr)) +\n#    geom_line(size = 1) +\n#    \n#    # just for demonstration purposes\n#    geom_abline(color = \"red\", linetype = \"dotted\") +\n#    \n#    theme_new +\n#    theme(\n#      legend.direction = \"vertical\",\n#      ) +\n#    labs(\n#        title = \"ROC Plot\"\n#        #subtitle = \"Performance of 3 Top Performing Models\"\n#    )\n#p1\n#\n\nknitr::include_graphics(\"./04_perf_meas_files/figure-html/unnamed-chunk-16-1.png\")\n\n\n\n\n\n\n\n\n\n#p2 &lt;- performance_tbl %&gt;%\n#  ggplot(aes(recall, precision)) +\n#    geom_line(size = 1) +\n#    theme_new + \n#    theme(\n#      legend.direction = \"vertical\",\n#      ) +\n#    labs(\n#        title = \"Precision vs Recall Plot\"\n#        #subtitle = \"Performance of 3 Top Performing Models\"\n#    )\n#p2\n\nknitr::include_graphics(\"./04_perf_meas_files/figure-html/unnamed-chunk-17-1.png\")\n\n\n\n\n\n\n\n\n\nranked_predictions_tbl &lt;- predictions_tbl %&gt;%\n    bind_cols(test_tbl) %&gt;%\n    select(predict:Yes, went_on_backorder) %&gt;%\n    # Sorting from highest to lowest class probability\n    arrange(desc(Yes))\n\ncalculated_gain_lift_tbl &lt;- ranked_predictions_tbl %&gt;%\n    mutate(ntile = ntile(Yes, n = 10)) %&gt;%\n    group_by(ntile) %&gt;%\n    summarise(\n        cases = n(),\n        responses = sum(went_on_backorder == \"Yes\")\n    ) %&gt;%\n    arrange(desc(ntile)) %&gt;%\n    \n    # Add group numbers (opposite of ntile)\n    mutate(group = row_number()) %&gt;%\n    select(group, cases, responses) %&gt;%\n    \n    # Calculations\n    mutate(\n        cumulative_responses = cumsum(responses),\n        pct_responses        = responses / sum(responses),\n        gain                 = cumsum(pct_responses),\n        cumulative_pct_cases = cumsum(cases) / sum(cases),\n        lift                 = gain / cumulative_pct_cases,\n        gain_baseline        = cumulative_pct_cases,\n        lift_baseline        = gain_baseline / cumulative_pct_cases\n    )\n\n\n#gain_lift_tbl &lt;- performance_h2o %&gt;%\n#    h2o.gainsLift() %&gt;%\n#    as.tibble()\n#\n#gain_transformed_tbl &lt;- gain_lift_tbl %&gt;% \n#    select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %&gt;%\n#    select(-contains(\"lift\")) %&gt;%\n#    mutate(baseline = cumulative_data_fraction) %&gt;%\n#    rename(gain     = cumulative_capture_rate) %&gt;%\n#    # prepare the data for the plotting (for the color and group aesthetics)\n#    pivot_longer(cols = c(gain, baseline), values_to = \"value\", names_to = \"key\")\n#\n#p3 &lt;- gain_transformed_tbl %&gt;%\n#    ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n#    geom_line(size = 1.5) +\n#    labs(\n#        title = \"Gain Chart\",\n#        x = \"Cumulative Data Fraction\",\n#        y = \"Gain\"\n#    ) +\n#    theme_new\n#p3\n\nknitr::include_graphics(\"./04_perf_meas_files/figure-html/unnamed-chunk-19-1.png\")\n\n\n\n\n\n\n\n\n\n#lift_transformed_tbl &lt;- gain_lift_tbl %&gt;% \n#    select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %&gt;%\n#    select(-contains(\"capture\")) %&gt;%\n#    mutate(baseline = 1) %&gt;%\n#    rename(lift = cumulative_lift) %&gt;%\n#    pivot_longer(cols = c(lift, baseline), values_to = \"value\", names_to = \"key\")\n#\n#p4 &lt;- lift_transformed_tbl %&gt;%\n#    ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n#    geom_line(size = 1.5) +\n#    labs(\n#        title = \"Lift Chart\",\n#        x = \"Cumulative Data Fraction\",\n#        y = \"Lift\"\n#    ) +\n#    theme_new\n#p4\n\nknitr::include_graphics(\"./04_perf_meas_files/figure-html/unnamed-chunk-20-1.png\")\n\n\n\n\n\n\n\n\n\nlibrary(cowplot)\n\n#&gt; \n#&gt; Attaching package: 'cowplot'\n\n\n#&gt; The following object is masked from 'package:lubridate':\n#&gt; \n#&gt;     stamp\n\nlibrary(glue)\n\n\n# Combine using cowplot\n   # \n#    # cowplot::get_legend extracts a legend from a ggplot object\n  #  p_legend &lt;- get_legend(p1)\n#    # Remove legend from p1\n #   p1 &lt;- p1 + theme(legend.position = \"none\")\n    \n    # cowplot::plt_grid() combines multiple ggplots into a single cowplot object\n#    p &lt;- cowplot::plot_grid(p1, p2, p3, p4, ncol = 2)\n #   p\nknitr::include_graphics(\"./04_perf_meas_files/figure-html/unnamed-chunk-22-1.png\")"
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html#total-covid-cases---time",
    "href": "content/01_journal/04_data_visualization.html#total-covid-cases---time",
    "title": "Data Visualization",
    "section": "\n2.1 Total covid cases - Time",
    "text": "2.1 Total covid cases - Time\n\n# Load required libraries\nlibrary(tidyverse)\nlibrary(ggrepel)\n\n# Load and preview the data\ncovid_data_tbl &lt;- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n\n#&gt; Rows: 399276 Columns: 67\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr   (4): iso_code, continent, location, tests_units\n#&gt; dbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\n#&gt; date  (1): date\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncovid_data_tbl %&gt;%\n  head(n=5)\n\n\n\n  \n\n\n# Define places to filter\nplaces &lt;- c('Germany', 'France', 'Spain', 'United Kingdom', 'United States')\n\n# Filter the data for selected places\ncovid_data_tbl_selected &lt;- covid_data_tbl %&gt;%\n  filter(location %in% places)\n\n# Get the range of dates\nlast_date &lt;- max(covid_data_tbl$date)\nfirst_date &lt;- min(covid_data_tbl$date)\n\n# Get the latest total cases for the US\nUS_covid_data_tbl &lt;- covid_data_tbl %&gt;%\n  filter(location == \"United States\")\n\nus_last_record &lt;- US_covid_data_tbl %&gt;%\n  filter(date == max(date))\n\nus_last_case &lt;- us_last_record$total_cases\nus_last_date &lt;- us_last_record$date\n\n# Get the latest total cases for Germany\nGermany_covid_data_tbl &lt;- covid_data_tbl %&gt;%\n  filter(location == \"Germany\")\n\ngermany_last_record &lt;- Germany_covid_data_tbl %&gt;%\n  filter(date == max(date))\n\ngermany_last_case &lt;- germany_last_record$total_cases\ngermany_last_date &lt;- germany_last_record$date\n\n# Plot\nggplot(covid_data_tbl_selected, aes(x = date, y = total_cases, color = location)) +\n  geom_line(size = 1.2) +\n  geom_label_repel(data = data.frame(date = us_last_date, total_cases = us_last_case, location = \"United States\"),\n                   aes(x = date, y = total_cases, label = paste(\"USA:\", format(us_last_case, big.mark = \",\"))),\n                   fill = \"purple\", color = \"white\", nudge_y = 5000000, size = 3) +\n  geom_label_repel(data = data.frame(date = germany_last_date, total_cases = germany_last_case, location = \"Germany\"),\n                   aes(x = date, y = total_cases, label = paste(\"Germany:\", format(germany_last_case, big.mark = \",\"))),\n                   fill = \"blue\", color = \"white\", nudge_y = 2000000, size = 3) +\n  labs(\n    subtitle = \"As of 09/05/2024\",\n    title = \"COVID-19 confirmed cases worldwide\",\n    x = \"\", \n    y = \"Cumulative Cases\",\n    color = \"Country\"\n  ) +\n  theme(\n    plot.title = element_text(\n      color = \"white\",\n      size = 16,\n      face = \"bold\"\n    ),\n    plot.subtitle = element_text(\n      color = \"white\",\n      size = 12\n    ),\n    legend.position = \"bottom\",\n    legend.background = element_rect(\n      fill = \"#222222\",\n      color = \"#aaaaaa\"\n    ),\n    legend.text = element_text(\n      color = \"#aaaaaa\"\n    ),\n    legend.title = element_text(\n      color = \"#aaaaaa\",\n      hjust = 0.5,\n      vjust = 0.5\n    ),\n    axis.text.x = element_text(\n      angle = 45,\n      hjust = 1,\n      color = \"#aaaaaa\"\n    ),\n    axis.text.y = element_text(\n      color = \"#aaaaaa\"\n    ),\n    axis.title.y = element_text(\n      color = \"white\",\n      size = 13,\n      face = \"bold\"\n    ),\n    plot.background = element_rect(\n      fill = \"#222222\"\n    ),\n    panel.background = element_rect(\n      fill = \"#222222\"\n    ),\n    panel.grid = element_line(\n      color = \"#888888\"\n    ),\n    panel.grid.minor = element_blank(),\n    legend.key = element_rect(\n      fill = \"#222222\"\n    )\n  ) +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%B '%y\") +\n  scale_y_continuous(breaks = c(0, 25000000, 50000000, 75000000),\n                     labels = c(\"0\", \"25M\", \"50M\", \"75M\")) +\n  scale_color_manual(values = c(\"Germany\" = \"red\", \n                                \"France\" = \"blue\", \n                                \"Spain\" = \"green\", \n                                \"United Kingdom\" = \"orange\", \n                                \"United States\" = \"purple\"),\n                     name = \"Country\",\n                     labels = c(\"Germany\", \"France\", \"Spain\", \"United Kingdom\", \"United States\")) +\n  guides(color = guide_legend(nrow = 2, byrow = TRUE))\n\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n#&gt; Warning: Removed 84 rows containing missing values or values outside the scale range\n#&gt; (`geom_line()`)."
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html#world-case-fatality-rate",
    "href": "content/01_journal/04_data_visualization.html#world-case-fatality-rate",
    "title": "Data Visualization",
    "section": "\n3.1 World case-fatality rate",
    "text": "3.1 World case-fatality rate\n\nlibrary(tidyverse)\nlibrary(maps)\nlibrary(purrr)\n\nworld &lt;- map_data(\"world\")\ncovid_data_tbl &lt;- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n\n#&gt; Rows: 399276 Columns: 67\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr   (4): iso_code, continent, location, tests_units\n#&gt; dbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\n#&gt; date  (1): date\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nlatest_date &lt;- covid_data_tbl$date %&gt;% max()\n\ncovid_data_tbl_plot &lt;- covid_data_tbl %&gt;%\n  select(location, total_cases, total_deaths, population) %&gt;%\n  drop_na() %&gt;%\n  group_by(location) %&gt;%\n  summarise(total_cases = last(total_cases), \n            total_deaths = last(total_deaths),\n            population = last(population),\n            mortality_rate = total_deaths / population,\n            case_fatality_rate = total_deaths / total_cases) \n\nworld_covid &lt;- covid_data_tbl_plot %&gt;%\n  mutate(location = case_when(\n    location == \"United Kingdom\" ~ \"UK\",\n    location == \"United States\" ~ \"USA\",\n    location == \"Democratic Republic of Congo\" ~ \"Democratic Republic of the Congo\",\n    TRUE ~ location\n  )) %&gt;%\n  right_join(world, c(\"location\" = \"region\")) \n\n# Visualize mortality rate\nggplot() +\n  geom_map(data = world_covid,\n           aes(x = long, y = lat, map_id = location, fill = mortality_rate),\n           col = \"white\",\n           map = world) +\n  scale_fill_gradient(low = \"#aa7776\", high = \"#8b0000\") +\n  theme(axis.title = element_blank(),\n        axis.text = element_blank(),\n        plot.background = element_rect(fill = \"#222222\"),\n        panel.background = element_rect(fill = \"#222222\"),\n        legend.background = element_rect(fill = \"#222222\", color = \"#aaaaaa\"),\n        legend.text = element_text(color = \"#aaaaaa\"),\n        legend.title = element_text(color = \"#aaaaaa\", hjust = 0.5, vjust = 0.5))\n\n#&gt; Warning in geom_map(data = world_covid, aes(x = long, y = lat, map_id =\n#&gt; location, : Ignoring unknown aesthetics: x and y\n\n\n\n\n\n\n\n# Visualize case-fatality rate\nggplot() +\n  geom_map(data = world_covid,\n           aes(x = long, y = lat, map_id = location, fill = case_fatality_rate),\n           col = \"white\",\n           map = world) +\n  scale_fill_gradient(low = \"#aa7776\", high = \"#8b0000\") +\n  theme(axis.title = element_blank(),\n        axis.text = element_blank(),\n        plot.background = element_rect(fill = \"#222222\"),\n        panel.background = element_rect(fill = \"#222222\"),\n        legend.background = element_rect(fill = \"#222222\", color = \"#aaaaaa\"),\n        legend.text = element_text(color = \"#aaaaaa\"),\n        legend.title = element_text(color = \"#aaaaaa\", hjust = 0.5, vjust = 0.5))\n\n#&gt; Warning in geom_map(data = world_covid, aes(x = long, y = lat, map_id =\n#&gt; location, : Ignoring unknown aesthetics: x and y"
  },
  {
    "objectID": "content/03_other/06_links.html",
    "href": "content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "content/03_other/06_links.html#r-and-r-studio",
    "href": "content/03_other/06_links.html#r-and-r-studio",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual ."
  },
  {
    "objectID": "content/03_other/06_links.html#additional-r-resources",
    "href": "content/03_other/06_links.html#additional-r-resources",
    "title": "Links",
    "section": "",
    "text": "Google is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html",
    "href": "content/01_journal/03_data_wrangling.html",
    "title": "03 Automated Machine Learning with H20 (I)",
    "section": "",
    "text": "1 Descriptive features and plot_ggpairs() to further investigate the features.\n\nlibrary(tidyverse)\nlibrary(GGally)\n\n##The provided R code snippet is performing the following tasks:\n\nLoading a CSV File: It reads a CSV file named WA_Fn-UseC_-HR-Employee-Attrition.csv located in the datasets-1067-1925 directory within the ss24-bdml-shamookh GitHub repository on your local machine. The read_csv function from the readr package (part of the tidyverse) is used for this task.\nInspecting the Data: After loading the data into a data frame called employee_attrition_tbl, it uses the glimpse function to display the structure and a preview of the data. The glimpse function provides a concise view of the data, showing the column names, data types, and a preview of the first few values in each column.\n\n\nemployee_attrition_tbl &lt;- read_csv(\"./03_ml_aut_files/datasets-1067-1925-WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n\n#&gt; Rows: 1470 Columns: 35\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr  (9): Attrition, BusinessTravel, Department, EducationField, Gender, Job...\n#&gt; dbl (26): Age, DailyRate, DistanceFromHome, Education, EmployeeCount, Employ...\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nemployee_attrition_tbl %&gt;%\n  glimpse()\n\n#&gt; Rows: 1,470\n#&gt; Columns: 35\n#&gt; $ Age                      &lt;dbl&gt; 41, 49, 37, 33, 27, 32, 59, 30, 38, 36, 35, 2…\n#&gt; $ Attrition                &lt;chr&gt; \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"…\n#&gt; $ BusinessTravel           &lt;chr&gt; \"Travel_Rarely\", \"Travel_Frequently\", \"Travel…\n#&gt; $ DailyRate                &lt;dbl&gt; 1102, 279, 1373, 1392, 591, 1005, 1324, 1358,…\n#&gt; $ Department               &lt;chr&gt; \"Sales\", \"Research & Development\", \"Research …\n#&gt; $ DistanceFromHome         &lt;dbl&gt; 1, 8, 2, 3, 2, 2, 3, 24, 23, 27, 16, 15, 26, …\n#&gt; $ Education                &lt;dbl&gt; 2, 1, 2, 4, 1, 2, 3, 1, 3, 3, 3, 2, 1, 2, 3, …\n#&gt; $ EducationField           &lt;chr&gt; \"Life Sciences\", \"Life Sciences\", \"Other\", \"L…\n#&gt; $ EmployeeCount            &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n#&gt; $ EmployeeNumber           &lt;dbl&gt; 1, 2, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16,…\n#&gt; $ EnvironmentSatisfaction  &lt;dbl&gt; 2, 3, 4, 4, 1, 4, 3, 4, 4, 3, 1, 4, 1, 2, 3, …\n#&gt; $ Gender                   &lt;chr&gt; \"Female\", \"Male\", \"Male\", \"Female\", \"Male\", \"…\n#&gt; $ HourlyRate               &lt;dbl&gt; 94, 61, 92, 56, 40, 79, 81, 67, 44, 94, 84, 4…\n#&gt; $ JobInvolvement           &lt;dbl&gt; 3, 2, 2, 3, 3, 3, 4, 3, 2, 3, 4, 2, 3, 3, 2, …\n#&gt; $ JobLevel                 &lt;dbl&gt; 2, 2, 1, 1, 1, 1, 1, 1, 3, 2, 1, 2, 1, 1, 1, …\n#&gt; $ JobRole                  &lt;chr&gt; \"Sales Executive\", \"Research Scientist\", \"Lab…\n#&gt; $ JobSatisfaction          &lt;dbl&gt; 4, 2, 3, 3, 2, 4, 1, 3, 3, 3, 2, 3, 3, 4, 3, …\n#&gt; $ MaritalStatus            &lt;chr&gt; \"Single\", \"Married\", \"Single\", \"Married\", \"Ma…\n#&gt; $ MonthlyIncome            &lt;dbl&gt; 5993, 5130, 2090, 2909, 3468, 3068, 2670, 269…\n#&gt; $ MonthlyRate              &lt;dbl&gt; 19479, 24907, 2396, 23159, 16632, 11864, 9964…\n#&gt; $ NumCompaniesWorked       &lt;dbl&gt; 8, 1, 6, 1, 9, 0, 4, 1, 0, 6, 0, 0, 1, 0, 5, …\n#&gt; $ Over18                   &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", …\n#&gt; $ OverTime                 &lt;chr&gt; \"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"No\", \"Yes\",…\n#&gt; $ PercentSalaryHike        &lt;dbl&gt; 11, 23, 15, 11, 12, 13, 20, 22, 21, 13, 13, 1…\n#&gt; $ PerformanceRating        &lt;dbl&gt; 3, 4, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, …\n#&gt; $ RelationshipSatisfaction &lt;dbl&gt; 1, 4, 2, 3, 4, 3, 1, 2, 2, 2, 3, 4, 4, 3, 2, …\n#&gt; $ StandardHours            &lt;dbl&gt; 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 8…\n#&gt; $ StockOptionLevel         &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 3, 1, 0, 2, 1, 0, 1, 1, 0, …\n#&gt; $ TotalWorkingYears        &lt;dbl&gt; 8, 10, 7, 8, 6, 8, 12, 1, 10, 17, 6, 10, 5, 3…\n#&gt; $ TrainingTimesLastYear    &lt;dbl&gt; 0, 3, 3, 3, 3, 2, 3, 2, 2, 3, 5, 3, 1, 2, 4, …\n#&gt; $ WorkLifeBalance          &lt;dbl&gt; 1, 3, 3, 3, 3, 2, 2, 3, 3, 2, 3, 3, 2, 3, 3, …\n#&gt; $ YearsAtCompany           &lt;dbl&gt; 6, 10, 0, 8, 2, 7, 1, 1, 9, 7, 5, 9, 5, 2, 4,…\n#&gt; $ YearsInCurrentRole       &lt;dbl&gt; 4, 7, 0, 7, 2, 7, 0, 0, 7, 7, 4, 5, 2, 2, 2, …\n#&gt; $ YearsSinceLastPromotion  &lt;dbl&gt; 0, 1, 0, 3, 2, 3, 0, 0, 1, 7, 0, 0, 4, 1, 0, …\n#&gt; $ YearsWithCurrManager     &lt;dbl&gt; 5, 7, 0, 0, 2, 6, 0, 0, 8, 7, 3, 8, 3, 2, 3, …\n\n\nThis output shows the number of rows and columns in the data frame, the names of the columns, the data types of each column (e.g.,  for double/numeric,  for character/string), and a preview of the first few values in each column. This provides a quick overview of the datasets structure and content.\n\nFunction Code: The function creates a pairwise plot matrix with color coding based on the Species variable.\n\n\n# Define the plot_ggpairs function\nplot_ggpairs &lt;- function(data, color = NULL, density_alpha = 0.5) {\n   \n    color_expr &lt;- enquo(color)\n   \n    if (rlang::quo_is_null(color_expr)) {\n       \n        g &lt;- data %&gt;%\n            ggpairs(lower = \"blank\",\n                    title = \"\",      # Set title to empty string\n                    subtitle = \"\")   # Set subtitle to empty string\n       \n    } else {\n       \n        color_name &lt;- quo_name(color_expr)\n       \n        g &lt;- data %&gt;%\n            ggpairs(mapping = aes_string(color = color_name),\n                    lower = \"blank\", legend = 1,\n                    diag = list(continuous = wrap(\"densityDiag\",\n                                                  alpha = density_alpha)),\n                    title = \"\",      # Set title to empty string\n                    subtitle = \"\")   # Set subtitle to empty string +\n            theme(legend.position = \"bottom\") +\n            theme(text = element_text(family = \"Times New Roman\", size = 18)) +\n            labs(title = element_text(face = \"bold\", size = 12),\n                 subtitle = element_text(face = \"bold\", size = 12),\n                 caption = element_text(size = 12))\n    }\n   \n    return(g)\n}\n\n\nPlotting Code: The plotting code reads the data, selects relevant columns, and uses the modified plot_ggpairs function to create a plot. It saves the plot as “Attrition_plot.png” and displays it in the R console or viewer.\n\n\n# Read the data\nemployee_attrition_tbl &lt;- read_csv(\"./03_ml_aut_files/datasets-1067-1925-WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n\n#&gt; Rows: 1470 Columns: 35\n#&gt; ── Column specification ────────────────────────────────────────────────────────\n#&gt; Delimiter: \",\"\n#&gt; chr  (9): Attrition, BusinessTravel, Department, EducationField, Gender, Job...\n#&gt; dbl (26): Age, DailyRate, DistanceFromHome, Education, EmployeeCount, Employ...\n#&gt; \n#&gt; ℹ Use `spec()` to retrieve the full column specification for this data.\n#&gt; ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Create the plot using plot_ggpairs function\nplot &lt;- employee_attrition_tbl %&gt;%\n    select(Attrition, MonthlyIncome, PercentSalaryHike, StockOptionLevel,\n           EnvironmentSatisfaction, WorkLifeBalance, JobInvolvement, OverTime,\n           TrainingTimesLastYear, YearsAtCompany, YearsSinceLastPromotion) %&gt;%\n    plot_ggpairs(color = Attrition)\n\n#&gt; Warning in warn_if_args_exist(list(...)): Extra arguments: \"subtitle\" are being\n#&gt; ignored.  If these are meant to be aesthetics, submit them using the 'mapping'\n#&gt; variable within ggpairs with ggplot2::aes or ggplot2::aes_string.\n\n\n#&gt; Warning: `aes_string()` was deprecated in ggplot2 3.0.0.\n#&gt; ℹ Please use tidy evaluation idioms with `aes()`.\n#&gt; ℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\n\n# Save the plot as \"Attrition_plot\"\nggsave(\"Attrition_plot.png\", plot, width = 25, height = 15)\n\n# Displaying of the saved plot\nknitr::include_graphics(\"./Attrition_plot.png\")\n\n\n\n\n\n\n\n\n\n\n2 Answer to the questions\n\nCompensation Features\n\nWhat can you deduce about the interaction between Monthly Income and Attrition?\n\n\nThose that are leaving have a lower Monthly Income\n\n\nWhat can you deduce about the interaction between Percent Salary Hike and Attrition?\n\n\nIt’s difficult to deduce anything based on the visualization\n\n\nWhat can you deduce about the interaction between Stock Option Level and Attrition?\n\n\nThose that are staying have a higher stock option level\n\n\n\nSurvey Results\n\nWhat can you deduce about the interaction between Environment Satisfaction and Attrition?\n\n\nA higher proportion of those leaving have a low environment satisfaction level\n\n\nWhat can you deduce about the interaction between Work Life Balance and Attrition\n\n\nThose that are staying have a higher density of 2’s and 3’\n\n\n\nPerformance Data\n\nWhat Can you deduce about the interaction between Job Involvement and Attrition?\n\n\nThose that are leaving have a lower density of 3’s and 4’s\n\n\n\nWork-Life Features\n\nWhat can you deduce about the interaction between Over Time and Attrition?\n\n\nThe proportion of those leaving that are working Over Time are high compared to those that are not leaving\n\n\n\nTraining and Education\n\nWhat can you deduce about the interaction between Training Times Last Year and Attrition c It’s difficult to deduce anything based on the visualization\n\n\n\nTime-Based Features\n\nWhat can you deduce about the interaction between Years At Company and Attrition b People that leave tend to have less working years at the company\nWhat can you deduce about the interaction between Years Since Last Promotion and Attrition?\n\n\nIt’s difficult to deduce anything based on the visualization"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#patent-dominance",
    "href": "content/01_journal/03_data_wrangling.html#patent-dominance",
    "title": "Data Wrangling",
    "section": "\n2.1 Patent Dominance",
    "text": "2.1 Patent Dominance\n\n# 01 Load libraries ----\n\nlibrary(vroom)\nlibrary(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.5\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#&gt; ✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ readr::col_character()   masks vroom::col_character()\n#&gt; ✖ readr::col_date()        masks vroom::col_date()\n#&gt; ✖ readr::col_datetime()    masks vroom::col_datetime()\n#&gt; ✖ readr::col_double()      masks vroom::col_double()\n#&gt; ✖ readr::col_factor()      masks vroom::col_factor()\n#&gt; ✖ readr::col_guess()       masks vroom::col_guess()\n#&gt; ✖ readr::col_integer()     masks vroom::col_integer()\n#&gt; ✖ readr::col_logical()     masks vroom::col_logical()\n#&gt; ✖ readr::col_number()      masks vroom::col_number()\n#&gt; ✖ readr::col_skip()        masks vroom::col_skip()\n#&gt; ✖ readr::col_time()        masks vroom::col_time()\n#&gt; ✖ readr::cols()            masks vroom::cols()\n#&gt; ✖ readr::date_names_lang() masks vroom::date_names_lang()\n#&gt; ✖ readr::default_locale()  masks vroom::default_locale()\n#&gt; ✖ dplyr::filter()          masks stats::filter()\n#&gt; ✖ readr::fwf_cols()        masks vroom::fwf_cols()\n#&gt; ✖ readr::fwf_empty()       masks vroom::fwf_empty()\n#&gt; ✖ readr::fwf_positions()   masks vroom::fwf_positions()\n#&gt; ✖ readr::fwf_widths()      masks vroom::fwf_widths()\n#&gt; ✖ dplyr::lag()             masks stats::lag()\n#&gt; ✖ readr::locale()          masks vroom::locale()\n#&gt; ✖ readr::output_column()   masks vroom::output_column()\n#&gt; ✖ readr::problems()        masks vroom::problems()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# 02 Wrangling Data ----\ncol_types &lt;- list(\n  id = col_character(),\n  date = col_date(\"%Y-%m-%d\"),\n  num_claims = col_double()\n)\n\npatent_tbl &lt;- vroom(\n  file       = \"Patent_data_reduced/patent.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\ncol_types &lt;- list(\n  id = col_character(),\n  type = col_character(),\n  organization = col_character()\n)\n\nassignee_tbl &lt;- vroom(\n  file       = \"Patent_data_reduced/assignee.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\ncol_types &lt;- list(\n  patent_id = col_character(),\n  assignee_id = col_character()\n)\n\npatent_assignee_tbl &lt;- vroom(\n  file       = \"Patent_data_reduced/patent_assignee.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\ncol_types &lt;- list(\n  patent_id = col_character(),\n  mainclass_id = col_character(),\n  sequence = col_integer()\n)\n\nuspc_tbl &lt;- vroom(\n  file       = \"Patent_data_reduced/uspc.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\nUS_top_10 &lt;- patent_assignee_tbl %&gt;%\n  group_by(assignee_id) %&gt;%\n  summarize(count = n()) %&gt;%\n  arrange(desc(count)) %&gt;%\n  left_join(assignee_tbl, c(\"assignee_id\" = \"id\"))\n\nChallange_1 &lt;- US_top_10$organization %&gt;%\n  head(n=50)\nChallange_1\n\n#&gt;  [1] \"International Business Machines Corporation\"          \n#&gt;  [2] \"Samsung Electronics Co., Ltd.\"                        \n#&gt;  [3] \"Canon Kabushiki Kaisha\"                               \n#&gt;  [4] \"Sony Corporation\"                                     \n#&gt;  [5] \"Microsoft Corporation\"                                \n#&gt;  [6] \"Google Inc.\"                                          \n#&gt;  [7] \"Kabushiki Kaisha Toshiba\"                             \n#&gt;  [8] \"QUALCOMM Incorporated\"                                \n#&gt;  [9] \"LG Electronics Inc.\"                                  \n#&gt; [10] \"Panasonic Corporation\"                                \n#&gt; [11] \"Apple Inc.\"                                           \n#&gt; [12] \"General Electric Company\"                             \n#&gt; [13] \"Fujitsu Limited\"                                      \n#&gt; [14] \"Seiko Epson Corporation\"                              \n#&gt; [15] \"Toyota Jidosha Kabushiki Kaisha\"                      \n#&gt; [16] \"Ricoh Company, Ltd.\"                                  \n#&gt; [17] \"Hewlett-Packard Development Company, L.P.\"            \n#&gt; [18] \"AT&T INTELLECTUAL PROPERTY I, L.P.\"                   \n#&gt; [19] \"Intel Corporation\"                                    \n#&gt; [20] \"Hon Hai Precision Industry Co., Ltd.\"                 \n#&gt; [21] \"Samsung Display Co., Ltd.\"                            \n#&gt; [22] \"Telefonaktiebolaget LM Ericsson (Publ)\"               \n#&gt; [23] \"GM Global Technology Operations LLC\"                  \n#&gt; [24] \"Taiwan Semiconductor Manufacturing Company, Ltd.\"     \n#&gt; [25] \"BlackBerry Limited\"                                   \n#&gt; [26] \"Honda Motor Co., Ltd.\"                                \n#&gt; [27] \"Broadcom Corporation\"                                 \n#&gt; [28] \"SEMICONDUCTOR ENERGY LABORATORY CO., LTD.\"            \n#&gt; [29] \"Robert Bosch GmbH\"                                    \n#&gt; [30] \"Brother Kogyo Kabushiki Kaisha\"                       \n#&gt; [31] \"Sharp Kabushiki Kaisha\"                               \n#&gt; [32] \"Cisco Technology, Inc.\"                               \n#&gt; [33] \"Siemens Aktiengesellschaft\"                           \n#&gt; [34] \"Hitachi, Ltd.\"                                        \n#&gt; [35] \"Micron Technology, Inc.\"                              \n#&gt; [36] \"FUJIFILM Corporation\"                                 \n#&gt; [37] \"NEC Corporation\"                                      \n#&gt; [38] \"Xerox Corporation\"                                    \n#&gt; [39] \"Koninklijke Philips Electronics N.V.\"                 \n#&gt; [40] \"The Boeing Company\"                                   \n#&gt; [41] \"Electronics and Telecommunications Research Institute\"\n#&gt; [42] \"Mitsubishi Electric Corporation\"                      \n#&gt; [43] \"Fuji Xerox Co., Ltd.\"                                 \n#&gt; [44] \"Texas Instruments Incorporated\"                       \n#&gt; [45] \"Denso Corporation\"                                    \n#&gt; [46] \"Ford Global Technologies, LLC\"                        \n#&gt; [47] \"Huawei Technologies Co., Ltd.\"                        \n#&gt; [48] \"Honeywell International Inc.\"                         \n#&gt; [49] \"Amazon Technologies, Inc.\"                            \n#&gt; [50] \"SK hynix Inc.\"\n\n\nTable 1: The 50 companies with the most patents(descending order)."
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#recent-patent-activity-2014-aug",
    "href": "content/01_journal/03_data_wrangling.html#recent-patent-activity-2014-aug",
    "title": "Data Wrangling",
    "section": "\n3.1 Recent Patent Activity (2014 Aug)",
    "text": "3.1 Recent Patent Activity (2014 Aug)\n\nS_2014_05 &lt;- patent_tbl %&gt;%\n  filter(date &gt;= \"2014-05-01\" & date &lt; \"2014-06-01\") %&gt;%\n  left_join(patent_assignee_tbl, c(\"id\" = \"patent_id\")) %&gt;%\n  left_join(assignee_tbl, c(\"assignee_id\" = \"id\")) %&gt;%\n  drop_na() %&gt;%\n  group_by(organization) %&gt;%\n  summarize(count =n()) %&gt;%\n  arrange(desc(count))\n\nChallange_2 &lt;-S_2014_05$organization %&gt;%\n  head(n=10)\nChallange_2\n\n#&gt;  [1] \"International Business Machines Corporation\"\n#&gt;  [2] \"Samsung Electronics Co., Ltd.\"              \n#&gt;  [3] \"Canon Kabushiki Kaisha\"                     \n#&gt;  [4] \"Microsoft Corporation\"                      \n#&gt;  [5] \"Sony Corporation\"                           \n#&gt;  [6] \"Kabushiki Kaisha Toshiba\"                   \n#&gt;  [7] \"Panasonic Corporation\"                      \n#&gt;  [8] \"QUALCOMM Incorporated\"                      \n#&gt;  [9] \"Apple Inc.\"                                 \n#&gt; [10] \"Google Inc.\"\n\n\nTable 2: Top 10 US companies with the most new granted patents in 2014 Aug."
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#innovation-in-tech",
    "href": "content/01_journal/03_data_wrangling.html#innovation-in-tech",
    "title": "Data Wrangling",
    "section": "\n4.1 Innovation in Tech",
    "text": "4.1 Innovation in Tech\n\nTop_mainclasses &lt;- uspc_tbl %&gt;%\n  inner_join(patent_assignee_tbl, c(\"patent_id\" = \"patent_id\")) %&gt;%\n  inner_join(assignee_tbl, c(\"assignee_id\"= \"id\")) %&gt;%\n  group_by(mainclass_id) %&gt;%\n  summarize(count = n()) %&gt;%\n  arrange(desc(count)) %&gt;%\n  head(n=5)\n\n#&gt; Warning in inner_join(., patent_assignee_tbl, c(patent_id = \"patent_id\")): Detected an unexpected many-to-many relationship between `x` and `y`.\n#&gt; ℹ Row 16 of `x` matches multiple rows in `y`.\n#&gt; ℹ Row 197969 of `y` matches multiple rows in `x`.\n#&gt; ℹ If a many-to-many relationship is expected, set `relationship =\n#&gt;   \"many-to-many\"` to silence this warning.\n\nChallange_3 &lt;- Top_mainclasses$mainclass_id %&gt;%\n  head(n=5)\nChallange_3\n\n#&gt; [1] \"257\" \"455\" \"370\" \"438\" \"709\"\n\n\nTable 3: Top 5 USPTO mainclasses for the worlds top ten companies.(descending order)"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html",
    "href": "content/01_journal/01_tidyverse.html",
    "title": "01 Tidyverse",
    "section": "",
    "text": "Last compiled: 2024-05-18\nThroughout the chapter, I gained proficiency in the fundamental aspects of the tidyverse library, encompassing essential skills in both data wrangling and data visualization."
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#sales-by-state",
    "href": "content/01_journal/01_tidyverse.html#sales-by-state",
    "title": "01 Tidyverse",
    "section": "\n2.1 Sales by State",
    "text": "2.1 Sales by State\n\n# Data Science at TUHH ------------------------------------------------------\n# SALES ANALYSIS ----\n\n# 1.0 Load libraries ----\nlibrary(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.5\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#&gt; ✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readxl)\n\n# 2.0 Importing Files ----\nbike_orderlines_wrangled_tbl &lt;- read_rds(\"01_tidyverse_files/bike_orderlines.rds\")\n\n# 3.0 Examining Data ----\n#bike_orderlines_wrangled_tbl %&gt;%\n#head(bike_orderlines_wrangled_tbl, n=7)\n\n# 4.0 Wrangling Data ----\nbike_orderlines_wrangled_tbl &lt;- bike_orderlines_wrangled_tbl %&gt;%\n  separate(col = location,\n           into = c(\"city\", \"state\"),\n           sep = \", \")\n\n# 5.0 Business insight ----\n#5.1 Challenge No. 1 - Sales by State ----\n\n#Step 1 - Manipulate----\nsales_by_state &lt;- bike_orderlines_wrangled_tbl %&gt;%\n  select(state, total_price) %&gt;%\n  group_by(state) %&gt;%\n  summarize(sales = sum(total_price))\nsales_by_state %&gt;% head(n=10)\n\n\n\n  \n\n\n#Step 2 - Visulaize----\nplot_1 &lt;- sales_by_state %&gt;%\n  ggplot(aes(x = state, y = sales),)+\n  geom_col(fill = \"blue\")+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))+\n  labs(title = \"Sales By State\")+\n  labs(y = \"Sales\")+labs(x = \"States\")+\n  theme(plot.title = element_text(size = 34))+\n  theme(axis.title.x = element_text(size = 28))+\n  theme(axis.title.y = element_text(size = 28))+\n  theme(axis.text.y = element_text(size = 14))+\n  theme(axis.text.x = element_text(size = 14))+\n  theme(text = element_text(family = \"Times New Roman\"))+\n  theme(axis.title = element_text(face=\"bold\"))+\n  theme(axis.text = element_text(face=\"bold\"))+\n  theme(plot.title = element_text(face=\"bold\"))+\n  theme(axis.title.x=element_text(colour=\"black\"))+\n  theme(axis.title.y=element_text(colour=\"black\"))+\n  theme(axis.text.x=element_text(colour=\"black\"))+\n  theme(axis.text.y=element_text(colour=\"black\"))+\n  theme(plot.title=element_text(hjust=0.5))\n\nplot_1\n\n\n\n\n\n\nggsave(\"01_tidyverse_files/figure-html/sales_by_state.png\", height = 7 , width = 12)\n\nThe above figure illustrates that North Rhine-Westphalia has the highest revenue among all states."
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#sales-by-state-by-year",
    "href": "content/01_journal/01_tidyverse.html#sales-by-state-by-year",
    "title": "01 Tidyverse",
    "section": "\n3.1 Sales by State by Year",
    "text": "3.1 Sales by State by Year\n\n# 5.2 Challenge No. 2 - sales by location and year (facet_wrap) ----\n\n#Step 1 - Manipulate----\nsales_by_state_by_year &lt;- bike_orderlines_wrangled_tbl %&gt;%\n  select(state, total_price, order_date) %&gt;%\n  mutate(year = year(order_date)) %&gt;%\n  group_by(year) %&gt;%\n  summarize(sales = sum(total_price), state = state)\n\n#&gt; Warning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\n#&gt; dplyr 1.1.0.\n#&gt; ℹ Please use `reframe()` instead.\n#&gt; ℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n#&gt;   always returns an ungrouped data frame and adjust accordingly.\n\n\n#&gt; `summarise()` has grouped output by 'year'. You can override using the\n#&gt; `.groups` argument.\n\nsales_by_state_by_year %&gt;% head(n=5)\n\n\n\n  \n\n\n#Step 2 - Visulaize----\nplot_2 &lt;- sales_by_state_by_year %&gt;%\n  ggplot(aes(x = year, y = sales, fill = state)) +\n  facet_wrap(~state) +\n  geom_col(fill = \"chocolate2\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))+\n  labs(title = \"Sales By Location and Year\")+\n  labs(x = \"Year\")+\n  labs(y = \"Sales\")+\n  theme(plot.title = element_text(size = 34))+\n  theme(axis.title.x = element_text(size = 28))+\n  theme(axis.title.y = element_text(size = 28))+\n  theme(axis.text.y = element_text(size = 14))+\n  theme(axis.text.x = element_text(size = 14))+\n  theme(text = element_text(family = \"Times New Roman\"))+\n  theme(axis.title = element_text(face=\"bold\"))+\n  theme(axis.text = element_text(face=\"bold\"))+\n  theme(plot.title = element_text(face=\"bold\"))+\n  theme(axis.title.x=element_text(colour=\"black\"))+\n  theme(axis.title.y=element_text(colour=\"black\"))+\n  theme(axis.text.x=element_text(colour=\"black\"))+\n  theme(axis.text.y=element_text(colour=\"black\"))+\n  theme(plot.title=element_text(hjust=0.5))+\n  theme(strip.text = element_text(size = 6, color = \"black\"))+\n  theme(strip.text = element_text(face = \"bold\"))\nplot_2\n\n\n\n\n\n\nggsave(\"01_tidyverse_files/figure-html/Sales_by_State_und_Location.png\", height = 15 , width = 20)"
  },
  {
    "objectID": "content/02_notes/05_class_notes.html",
    "href": "content/02_notes/05_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "IMPORTANT: You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.\nThis is an .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header."
  },
  {
    "objectID": "content/01_journal/05_lime.html",
    "href": "content/01_journal/05_lime.html",
    "title": "05 LIME",
    "section": "",
    "text": "library(h2o)\nlibrary(recipes)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(lime)\n\n\nprocess_hr_data_readable &lt;- function(data, definitions_tbl) {\n\n    definitions_list &lt;- definitions_tbl %&gt;%\n        fill(...1, .direction = \"down\") %&gt;%\n        filter(!is.na(...2)) %&gt;%\n        separate(...2, into = c(\"key\", \"value\"), sep = \" '\", remove = TRUE) %&gt;%\n        rename(column_name = ...1) %&gt;%\n        mutate(key = as.numeric(key)) %&gt;%\n        mutate(value = value %&gt;% str_replace(pattern = \"'\", replacement = \"\")) %&gt;%\n        split(.$column_name) %&gt;%\n        map(~ select(., -column_name)) %&gt;%\n        map(~ mutate(., value = as_factor(value))) \n    \n    for (i in seq_along(definitions_list)) {\n        list_name &lt;- names(definitions_list)[i]\n        colnames(definitions_list[[i]]) &lt;- c(list_name, paste0(list_name, \"_value\"))\n    }\n    \n    data_merged_tbl &lt;- list(HR_Data = data) %&gt;%\n        append(definitions_list, after = 1) %&gt;%\n        reduce(left_join) %&gt;%\n        select(-one_of(names(definitions_list))) %&gt;%\n        set_names(str_replace_all(names(.), pattern = \"_value\", \n                                            replacement = \"\")) %&gt;%\n        select(sort(names(.))) %&gt;%\n        mutate_if(is.character, as.factor) %&gt;%\n        mutate(\n            BusinessTravel = BusinessTravel %&gt;% fct_relevel(\"Non-Travel\", \n                                                            \"Travel_Rarely\", \n                                                            \"Travel_Frequently\"),\n            MaritalStatus  = MaritalStatus %&gt;% fct_relevel(\"Single\", \n                                                           \"Married\", \n                                                           \"Divorced\")\n        )\n    \n    return(data_merged_tbl)\n    \n}\n\n\nemployee_attrition_tbl &lt;- read_csv(\"./03_ml_aut_files/datasets-1067-1925-WA_Fn-UseC_-HR-Employee-Attrition.txt\")\ndefinitions_raw_tbl    &lt;- read_excel(\"./03_ml_aut_files/data_definitions.xlsx\", sheet = 1, col_names = FALSE)\n\nemployee_attrition_readable_tbl &lt;- process_hr_data_readable(employee_attrition_tbl, definitions_raw_tbl)\n\n# Split into test and train\nset.seed(seed = 1113)\nsplit_obj &lt;- rsample::initial_split(employee_attrition_readable_tbl, prop = 0.85)\n\n# Assign training and test data\ntrain_readable_tbl &lt;- training(split_obj)\ntest_readable_tbl  &lt;- testing(split_obj)\n\nrecipe_obj &lt;- recipe(Attrition ~ ., data = train_readable_tbl) %&gt;%\n                step_zv(all_predictors()) %&gt;%\n                step_mutate_at(c(\"JobLevel\", \"StockOptionLevel\"), fn = as.factor) %&gt;% \n                prep()\n\ntrain_tbl &lt;- bake(recipe_obj, new_data = train_readable_tbl)\ntest_tbl  &lt;- bake(recipe_obj, new_data = test_readable_tbl)\n\nh2o.init()\n\n#&gt;  Connection successful!\n#&gt; \n#&gt; R is connected to the H2O cluster: \n#&gt;     H2O cluster uptime:         1 hours 10 minutes \n#&gt;     H2O cluster timezone:       Asia/Karachi \n#&gt;     H2O data parsing timezone:  UTC \n#&gt;     H2O cluster version:        3.36.0.4 \n#&gt;     H2O cluster version age:    2 years, 2 months and 24 days !!! \n#&gt;     H2O cluster name:           H2O_started_from_R_Crown_Tech_pgz902 \n#&gt;     H2O cluster total nodes:    1 \n#&gt;     H2O cluster total memory:   3.79 GB \n#&gt;     H2O cluster total cores:    8 \n#&gt;     H2O cluster allowed cores:  8 \n#&gt;     H2O cluster healthy:        TRUE \n#&gt;     H2O Connection ip:          localhost \n#&gt;     H2O Connection port:        54321 \n#&gt;     H2O Connection proxy:       NA \n#&gt;     H2O Internal Security:      FALSE \n#&gt;     R Version:                  R version 4.4.1 (2024-06-14 ucrt)\n\n#automl_leader &lt;- h2o.loadModel(\"./04_perf_meas_files/StackedEnsemble_BestOfFamily_2_AutoML_1_20220612_170511\")\nsplit_h2o &lt;- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)\n\n#&gt; \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\ntrain_h2o &lt;- split_h2o[[1]]\nvalid_h2o &lt;- split_h2o[[2]]\ntest_h2o  &lt;- as.h2o(test_tbl)\n\n#&gt; \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n# Set the target and predictors\ny &lt;- \"Attrition\"\nx &lt;- setdiff(names(train_h2o), y)\n\nautoml_models_h2o &lt;- h2o.automl(\n  x = x,\n  y = y,\n  training_frame    = train_h2o,\n  validation_frame  = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs  = 30,\n  nfolds            = 5 \n)\n\n#&gt; \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n#&gt; 23:26:08.646: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n#&gt; 23:26:08.666: AutoML: XGBoost is not available; skipping it.\n#&gt; 23:26:08.673: Step 'best_of_family_xgboost' not defined in provider 'StackedEnsemble': skipping it.\n#&gt; 23:26:08.673: Step 'all_xgboost' not defined in provider 'StackedEnsemble': skipping it.\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==============                                                        |  19%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |===================================================                   |  74%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |======================================================================| 100%\n\nautoml_leader &lt;- automl_models_h2o@leader\n\n\nexplainer &lt;- train_tbl %&gt;%\n    select(-Attrition) %&gt;%\n    lime(\n        model           = automl_leader,\n        bin_continuous  = TRUE,\n        n_bins          = 4,\n        quantile_bins   = TRUE\n    )\n\nexplainer\n\n#&gt; $model\n#&gt; Model Details:\n#&gt; ==============\n#&gt; \n#&gt; H2OBinomialModel: stackedensemble\n#&gt; Model ID:  StackedEnsemble_AllModels_1_AutoML_5_20240623_232608 \n#&gt; Number of Base Models: 6\n#&gt; \n#&gt; Base Models (count by algorithm type):\n#&gt; \n#&gt; drf gbm glm \n#&gt;   1   4   1 \n#&gt; \n#&gt; Metalearner:\n#&gt; \n#&gt; Metalearner algorithm: glm\n#&gt; Metalearner cross-validation fold assignment:\n#&gt;   Fold assignment scheme: AUTO\n#&gt;   Number of folds: 5\n#&gt;   Fold column: NULL\n#&gt; Metalearner hyperparameters: \n#&gt; \n#&gt; \n#&gt; H2OBinomialMetrics: stackedensemble\n#&gt; ** Reported on training data. **\n#&gt; \n#&gt; MSE:  0.06104302\n#&gt; RMSE:  0.2470689\n#&gt; LogLoss:  0.2222516\n#&gt; Mean Per-Class Error:  0.1471841\n#&gt; AUC:  0.9242698\n#&gt; AUCPR:  0.8191139\n#&gt; Gini:  0.8485397\n#&gt; \n#&gt; Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#&gt;         No Yes    Error      Rate\n#&gt; No     876  33 0.036304   =33/909\n#&gt; Yes     40 115 0.258065   =40/155\n#&gt; Totals 916 148 0.068609  =73/1064\n#&gt; \n#&gt; Maximum Metrics: Maximum metrics at their respective thresholds\n#&gt;                         metric threshold      value idx\n#&gt; 1                       max f1  0.336077   0.759076 121\n#&gt; 2                       max f2  0.199598   0.766979 179\n#&gt; 3                 max f0point5  0.528407   0.815109  75\n#&gt; 4                 max accuracy  0.358321   0.932331 115\n#&gt; 5                max precision  0.968708   1.000000   0\n#&gt; 6                   max recall  0.003883   1.000000 391\n#&gt; 7              max specificity  0.968708   1.000000   0\n#&gt; 8             max absolute_mcc  0.336077   0.719362 121\n#&gt; 9   max min_per_class_accuracy  0.185371   0.858065 190\n#&gt; 10 max mean_per_class_accuracy  0.199598   0.865925 179\n#&gt; 11                     max tns  0.968708 909.000000   0\n#&gt; 12                     max fns  0.968708 154.000000   0\n#&gt; 13                     max fps  0.000456 909.000000 399\n#&gt; 14                     max tps  0.003883 155.000000 391\n#&gt; 15                     max tnr  0.968708   1.000000   0\n#&gt; 16                     max fnr  0.968708   0.993548   0\n#&gt; 17                     max fpr  0.000456   1.000000 399\n#&gt; 18                     max tpr  0.003883   1.000000 391\n#&gt; \n#&gt; Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`\n#&gt; H2OBinomialMetrics: stackedensemble\n#&gt; ** Reported on validation data. **\n#&gt; \n#&gt; MSE:  0.1017679\n#&gt; RMSE:  0.3190108\n#&gt; LogLoss:  0.3361267\n#&gt; Mean Per-Class Error:  0.1923559\n#&gt; AUC:  0.867705\n#&gt; AUCPR:  0.7276925\n#&gt; Gini:  0.73541\n#&gt; \n#&gt; Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#&gt;         No Yes    Error     Rate\n#&gt; No     133  14 0.095238  =14/147\n#&gt; Yes     11  27 0.289474   =11/38\n#&gt; Totals 144  41 0.135135  =25/185\n#&gt; \n#&gt; Maximum Metrics: Maximum metrics at their respective thresholds\n#&gt;                         metric threshold      value idx\n#&gt; 1                       max f1  0.308235   0.683544  40\n#&gt; 2                       max f2  0.292557   0.714286  43\n#&gt; 3                 max f0point5  0.483671   0.714286  21\n#&gt; 4                 max accuracy  0.483671   0.870270  21\n#&gt; 5                max precision  0.917872   1.000000   0\n#&gt; 6                   max recall  0.019111   1.000000 142\n#&gt; 7              max specificity  0.917872   1.000000   0\n#&gt; 8             max absolute_mcc  0.308235   0.598489  40\n#&gt; 9   max min_per_class_accuracy  0.165549   0.768707  63\n#&gt; 10 max mean_per_class_accuracy  0.292557   0.813999  43\n#&gt; 11                     max tns  0.917872 147.000000   0\n#&gt; 12                     max fns  0.917872  37.000000   0\n#&gt; 13                     max fps  0.000864 147.000000 184\n#&gt; 14                     max tps  0.019111  38.000000 142\n#&gt; 15                     max tnr  0.917872   1.000000   0\n#&gt; 16                     max fnr  0.917872   0.973684   0\n#&gt; 17                     max fpr  0.000864   1.000000 184\n#&gt; 18                     max tpr  0.019111   1.000000 142\n#&gt; \n#&gt; Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`\n#&gt; H2OBinomialMetrics: stackedensemble\n#&gt; ** Reported on cross-validation data. **\n#&gt; ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n#&gt; \n#&gt; MSE:  0.08453324\n#&gt; RMSE:  0.290746\n#&gt; LogLoss:  0.3002573\n#&gt; Mean Per-Class Error:  0.2106462\n#&gt; AUC:  0.8424075\n#&gt; AUCPR:  0.6198857\n#&gt; Gini:  0.6848149\n#&gt; \n#&gt; Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#&gt;         No Yes    Error       Rate\n#&gt; No     831  78 0.085809    =78/909\n#&gt; Yes     52 103 0.335484    =52/155\n#&gt; Totals 883 181 0.122180  =130/1064\n#&gt; \n#&gt; Maximum Metrics: Maximum metrics at their respective thresholds\n#&gt;                         metric threshold      value idx\n#&gt; 1                       max f1  0.272880   0.613095 144\n#&gt; 2                       max f2  0.187727   0.648253 193\n#&gt; 3                 max f0point5  0.432194   0.662432  84\n#&gt; 4                 max accuracy  0.432194   0.898496  84\n#&gt; 5                max precision  0.978744   1.000000   0\n#&gt; 6                   max recall  0.000602   1.000000 399\n#&gt; 7              max specificity  0.978744   1.000000   0\n#&gt; 8             max absolute_mcc  0.384467   0.544636  98\n#&gt; 9   max min_per_class_accuracy  0.156106   0.774194 215\n#&gt; 10 max mean_per_class_accuracy  0.269348   0.790929 147\n#&gt; 11                     max tns  0.978744 909.000000   0\n#&gt; 12                     max fns  0.978744 154.000000   0\n#&gt; 13                     max fps  0.000602 909.000000 399\n#&gt; 14                     max tps  0.000602 155.000000 399\n#&gt; 15                     max tnr  0.978744   1.000000   0\n#&gt; 16                     max fnr  0.978744   0.993548   0\n#&gt; 17                     max fpr  0.000602   1.000000 399\n#&gt; 18                     max tpr  0.000602   1.000000 399\n#&gt; \n#&gt; Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`\n#&gt; \n#&gt; $preprocess\n#&gt; function (x) \n#&gt; x\n#&gt; &lt;bytecode: 0x000001d2b18703a8&gt;\n#&gt; &lt;environment: 0x000001d2b18620d0&gt;\n#&gt; \n#&gt; $bin_continuous\n#&gt; [1] TRUE\n#&gt; \n#&gt; $n_bins\n#&gt; [1] 4\n#&gt; \n#&gt; $quantile_bins\n#&gt; [1] TRUE\n#&gt; \n#&gt; $use_density\n#&gt; [1] TRUE\n#&gt; \n#&gt; $feature_type\n#&gt;                      Age           BusinessTravel                DailyRate \n#&gt;                \"numeric\"                 \"factor\"                \"numeric\" \n#&gt;               Department         DistanceFromHome                Education \n#&gt;                 \"factor\"                \"numeric\"                 \"factor\" \n#&gt;           EducationField           EmployeeNumber  EnvironmentSatisfaction \n#&gt;                 \"factor\"                \"numeric\"                 \"factor\" \n#&gt;                   Gender               HourlyRate           JobInvolvement \n#&gt;                 \"factor\"                \"numeric\"                 \"factor\" \n#&gt;                 JobLevel                  JobRole          JobSatisfaction \n#&gt;                 \"factor\"                 \"factor\"                 \"factor\" \n#&gt;            MaritalStatus            MonthlyIncome              MonthlyRate \n#&gt;                 \"factor\"                \"numeric\"                \"numeric\" \n#&gt;       NumCompaniesWorked                 OverTime        PercentSalaryHike \n#&gt;                \"numeric\"                 \"factor\"                \"numeric\" \n#&gt;        PerformanceRating RelationshipSatisfaction         StockOptionLevel \n#&gt;                 \"factor\"                 \"factor\"                 \"factor\" \n#&gt;        TotalWorkingYears    TrainingTimesLastYear          WorkLifeBalance \n#&gt;                \"numeric\"                \"numeric\"                 \"factor\" \n#&gt;           YearsAtCompany       YearsInCurrentRole  YearsSinceLastPromotion \n#&gt;                \"numeric\"                \"numeric\"                \"numeric\" \n#&gt;     YearsWithCurrManager \n#&gt;                \"numeric\" \n#&gt; \n#&gt; $bin_cuts\n#&gt; $bin_cuts$Age\n#&gt;   0%  25%  50%  75% 100% \n#&gt;   18   30   36   43   60 \n#&gt; \n#&gt; $bin_cuts$BusinessTravel\n#&gt; NULL\n#&gt; \n#&gt; $bin_cuts$DailyRate\n#&gt;   0%  25%  50%  75% 100% \n#&gt;  102  465  797 1147 1499 \n#&gt; \n#&gt; $bin_cuts$Department\n#&gt; NULL\n#&gt; \n#&gt; $bin_cuts$DistanceFromHome\n#&gt;   0%  25%  50%  75% 100% \n#&gt;    1    2    7   14   29 \n#&gt; \n#&gt; $bin_cuts$Education\n#&gt; NULL\n#&gt; \n#&gt; $bin_cuts$EducationField\n#&gt; NULL\n#&gt; \n#&gt; $bin_cuts$EmployeeNumber\n#&gt;   0%  25%  50%  75% 100% \n#&gt;    1  511 1040 1573 2065 \n#&gt; \n#&gt; $bin_cuts$EnvironmentSatisfaction\n#&gt; NULL\n#&gt; \n#&gt; $bin_cuts$Gender\n#&gt; NULL\n#&gt; \n#&gt; $bin_cuts$HourlyRate\n#&gt;   0%  25%  50%  75% 100% \n#&gt;   30   49   66   83  100 \n#&gt; \n#&gt; $bin_cuts$JobInvolvement\n#&gt; NULL\n#&gt; \n#&gt; $bin_cuts$JobLevel\n#&gt; NULL\n#&gt; \n#&gt; $bin_cuts$JobRole\n#&gt; NULL\n#&gt; \n#&gt; $bin_cuts$JobSatisfaction\n#&gt; NULL\n#&gt; \n#&gt; $bin_cuts$MaritalStatus\n#&gt; NULL\n#&gt; \n#&gt; $bin_cuts$MonthlyIncome\n#&gt;    0%   25%   50%   75%  100% \n#&gt;  1051  2929  4908  8474 19999 \n#&gt; \n#&gt; $bin_cuts$MonthlyRate\n#&gt;    0%   25%   50%   75%  100% \n#&gt;  2094  8423 14470 20689 26968 \n#&gt; \n#&gt; $bin_cuts$NumCompaniesWorked\n#&gt;   0%  25%  50%  75% 100% \n#&gt;    0    1    2    4    9 \n#&gt; \n#&gt; $bin_cuts$OverTime\n#&gt; NULL\n#&gt; \n#&gt; $bin_cuts$PercentSalaryHike\n#&gt;   0%  25%  50%  75% 100% \n#&gt;   11   12   14   18   25 \n#&gt; \n#&gt; $bin_cuts$PerformanceRating\n#&gt; NULL\n#&gt; \n#&gt; $bin_cuts$RelationshipSatisfaction\n#&gt; NULL\n#&gt; \n#&gt; $bin_cuts$StockOptionLevel\n#&gt; NULL\n#&gt; \n#&gt; $bin_cuts$TotalWorkingYears\n#&gt;   0%  25%  50%  75% 100% \n#&gt;    0    6   10   15   38 \n#&gt; \n#&gt; $bin_cuts$TrainingTimesLastYear\n#&gt;   0%  25%  50% 100% \n#&gt;    0    2    3    6 \n#&gt; \n#&gt; $bin_cuts$WorkLifeBalance\n#&gt; NULL\n#&gt; \n#&gt; $bin_cuts$YearsAtCompany\n#&gt;   0%  25%  50%  75% 100% \n#&gt;    0    3    5    9   37 \n#&gt; \n#&gt; $bin_cuts$YearsInCurrentRole\n#&gt;   0%  25%  50%  75% 100% \n#&gt;    0    2    3    7   18 \n#&gt; \n#&gt; $bin_cuts$YearsSinceLastPromotion\n#&gt;   0%  50%  75% 100% \n#&gt;    0    1    2   15 \n#&gt; \n#&gt; $bin_cuts$YearsWithCurrManager\n#&gt;   0%  25%  50%  75% 100% \n#&gt;    0    2    3    7   17 \n#&gt; \n#&gt; \n#&gt; $feature_distribution\n#&gt; $feature_distribution$Age\n#&gt; \n#&gt;         1         2         3         4 \n#&gt; 0.2602082 0.2834267 0.2217774 0.2345877 \n#&gt; \n#&gt; $feature_distribution$BusinessTravel\n#&gt; \n#&gt;        Non-Travel     Travel_Rarely Travel_Frequently \n#&gt;         0.1000801         0.7181745         0.1817454 \n#&gt; \n#&gt; $feature_distribution$DailyRate\n#&gt; \n#&gt;         1         2         3         4 \n#&gt; 0.2514011 0.2489992 0.2497998 0.2497998 \n#&gt; \n#&gt; $feature_distribution$Department\n#&gt; \n#&gt;        Human Resources Research & Development                  Sales \n#&gt;             0.04323459             0.65092074             0.30584468 \n#&gt; \n#&gt; $feature_distribution$DistanceFromHome\n#&gt; \n#&gt;         1         2         3         4 \n#&gt; 0.2954363 0.2369896 0.2241793 0.2433947 \n#&gt; \n#&gt; $feature_distribution$Education\n#&gt; \n#&gt; Below College       College      Bachelor        Master        Doctor \n#&gt;    0.11689351    0.18895116    0.38510809    0.27461970    0.03442754 \n#&gt; \n#&gt; $feature_distribution$EducationField\n#&gt; \n#&gt;  Human Resources    Life Sciences        Marketing          Medical \n#&gt;       0.01761409       0.41793435       0.10888711       0.31144916 \n#&gt;            Other Technical Degree \n#&gt;       0.05444355       0.08967174 \n#&gt; \n#&gt; $feature_distribution$EmployeeNumber\n#&gt; \n#&gt;         1         2         3         4 \n#&gt; 0.2506005 0.2497998 0.2497998 0.2497998 \n#&gt; \n#&gt; $feature_distribution$EnvironmentSatisfaction\n#&gt; \n#&gt;       Low    Medium      High Very High \n#&gt; 0.1913531 0.1961569 0.3018415 0.3106485 \n#&gt; \n#&gt; $feature_distribution$Gender\n#&gt; \n#&gt;    Female      Male \n#&gt; 0.4123299 0.5876701 \n#&gt; \n#&gt; $feature_distribution$HourlyRate\n#&gt; \n#&gt;         1         2         3         4 \n#&gt; 0.2618094 0.2473979 0.2449960 0.2457966 \n#&gt; \n#&gt; $feature_distribution$JobInvolvement\n#&gt; \n#&gt;        Low     Medium       High  Very High \n#&gt; 0.05684548 0.25780624 0.58927142 0.09607686 \n#&gt; \n#&gt; $feature_distribution$JobLevel\n#&gt; \n#&gt;          1          2          3          4          5 \n#&gt; 0.36829464 0.36509207 0.14651721 0.07526021 0.04483587 \n#&gt; \n#&gt; $feature_distribution$JobRole\n#&gt; \n#&gt; Healthcare Representative           Human Resources     Laboratory Technician \n#&gt;                0.08646918                0.03682946                0.18174540 \n#&gt;                   Manager    Manufacturing Director         Research Director \n#&gt;                0.06885508                0.09927942                0.05924740 \n#&gt;        Research Scientist           Sales Executive      Sales Representative \n#&gt;                0.18654924                0.22337870                0.05764612 \n#&gt; \n#&gt; $feature_distribution$JobSatisfaction\n#&gt; \n#&gt;       Low    Medium      High Very High \n#&gt; 0.1873499 0.1985588 0.3018415 0.3122498 \n#&gt; \n#&gt; $feature_distribution$MaritalStatus\n#&gt; \n#&gt;    Single   Married  Divorced \n#&gt; 0.3306645 0.4571657 0.2121697 \n#&gt; \n#&gt; $feature_distribution$MonthlyIncome\n#&gt; \n#&gt;         1         2         3         4 \n#&gt; 0.2506005 0.2497998 0.2497998 0.2497998 \n#&gt; \n#&gt; $feature_distribution$MonthlyRate\n#&gt; \n#&gt;         1         2         3         4 \n#&gt; 0.2506005 0.2497998 0.2497998 0.2497998 \n#&gt; \n#&gt; $feature_distribution$NumCompaniesWorked\n#&gt; \n#&gt;          1          2          3          4 \n#&gt; 0.48118495 0.09927942 0.20496397 0.21457166 \n#&gt; \n#&gt; $feature_distribution$OverTime\n#&gt; \n#&gt;        No       Yes \n#&gt; 0.7165733 0.2834267 \n#&gt; \n#&gt; $feature_distribution$PercentSalaryHike\n#&gt; \n#&gt;         1         2         3         4 \n#&gt; 0.2866293 0.2738191 0.2289832 0.2105685 \n#&gt; \n#&gt; $feature_distribution$PerformanceRating\n#&gt; \n#&gt;         Low        Good   Excellent Outstanding \n#&gt;   0.0000000   0.0000000   0.8414732   0.1585268 \n#&gt; \n#&gt; $feature_distribution$RelationshipSatisfaction\n#&gt; \n#&gt;       Low    Medium      High Very High \n#&gt; 0.1889512 0.2161729 0.3018415 0.2930344 \n#&gt; \n#&gt; $feature_distribution$StockOptionLevel\n#&gt; \n#&gt;          0          1          2          3 \n#&gt; 0.43554844 0.40592474 0.10168135 0.05684548 \n#&gt; \n#&gt; $feature_distribution$TotalWorkingYears\n#&gt; \n#&gt;         1         2         3         4 \n#&gt; 0.3050440 0.3306645 0.1224980 0.2417934 \n#&gt; \n#&gt; $feature_distribution$TrainingTimesLastYear\n#&gt; \n#&gt;         1         2         3 \n#&gt; 0.4603683 0.3306645 0.2089672 \n#&gt; \n#&gt; $feature_distribution$WorkLifeBalance\n#&gt; \n#&gt;        Bad       Good     Better       Best \n#&gt; 0.05204163 0.22497998 0.61889512 0.10408327 \n#&gt; \n#&gt; $feature_distribution$YearsAtCompany\n#&gt; \n#&gt;         1         2         3         4 \n#&gt; 0.3226581 0.2137710 0.2217774 0.2417934 \n#&gt; \n#&gt; $feature_distribution$YearsInCurrentRole\n#&gt; \n#&gt;          1          2          3          4 \n#&gt; 0.46757406 0.08726982 0.27542034 0.16973579 \n#&gt; \n#&gt; $feature_distribution$YearsSinceLastPromotion\n#&gt; \n#&gt;         1         2         3 \n#&gt; 0.6413131 0.1120897 0.2465973 \n#&gt; \n#&gt; $feature_distribution$YearsWithCurrManager\n#&gt; \n#&gt;          1          2          3          4 \n#&gt; 0.46357086 0.09767814 0.25300240 0.18574860 \n#&gt; \n#&gt; \n#&gt; attr(,\"class\")\n#&gt; [1] \"data_frame_explainer\" \"explainer\"            \"list\"\n\n\n\nexplanation &lt;- test_tbl %&gt;%\n    slice(1:20) %&gt;%\n    select(-Attrition) %&gt;%\n    lime::explain(\n    \n        # Pass our explainer object\n        explainer = explainer,\n        # Because it is a binary classification model: 1\n        n_labels   = 1,\n        # number of features to be returned\n        n_features = 8,\n        # number of localized linear models\n        n_permutations = 5000,\n        # Let's start with 1\n        kernel_width   = 1\n    )\n\n#&gt; \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n#&gt; \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\nexplanation\n\n\n  \n\n\n\n\nexplanation %&gt;% \n  as.tibble()\n\n\n  \n\n\ncase_1 &lt;- explanation %&gt;%\n    filter(case == 1)\n\ncase_1 %&gt;%\n    plot_features()\n\n\n\n\n\n\n\ncase_1 %&gt;%\n  ggplot(aes(y=feature_desc, x =feature_weight)) +\n  geom_col(aes(fill = feature_weight &gt; 0)) +\n  xlab(\"Weight\") + \n  ylab(\"Feature\") +\n  scale_fill_discrete(name = \"\", labels = c(\"Contradicts\", \"Supports\")) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nexplanation %&gt;%\n  mutate(case = as.double(case)) %&gt;%\n  ggplot(aes(y=feature_desc, x =case, fill = feature_weight)) +\n  geom_tile() +\n  facet_wrap(~label)"
  },
  {
    "objectID": "content/01_journal/06_deep_learning.html",
    "href": "content/01_journal/06_deep_learning.html",
    "title": "06 Deep Learning",
    "section": "",
    "text": "library(tidyverse)\nlibrary(keras)\nlibrary(lime)\nlibrary(rsample)\nlibrary(recipes)\nlibrary(yardstick)\nlibrary(corrr)\nlibrary(reticulate)\nlibrary(tensorflow)\n\n\nchurn_data_raw &lt;- read.csv(\"./06_dl_files/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n\nglimpse(churn_data_raw)\n\n#&gt; Rows: 7,043\n#&gt; Columns: 21\n#&gt; $ customerID       &lt;chr&gt; \"7590-VHVEG\", \"5575-GNVDE\", \"3668-QPYBK\", \"7795-CFOCW…\n#&gt; $ gender           &lt;chr&gt; \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"Female\",…\n#&gt; $ SeniorCitizen    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ Partner          &lt;chr&gt; \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes…\n#&gt; $ Dependents       &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\"…\n#&gt; $ tenure           &lt;int&gt; 1, 34, 2, 45, 2, 8, 22, 10, 28, 62, 13, 16, 58, 49, 2…\n#&gt; $ PhoneService     &lt;chr&gt; \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", …\n#&gt; $ MultipleLines    &lt;chr&gt; \"No phone service\", \"No\", \"No\", \"No phone service\", \"…\n#&gt; $ InternetService  &lt;chr&gt; \"DSL\", \"DSL\", \"DSL\", \"DSL\", \"Fiber optic\", \"Fiber opt…\n#&gt; $ OnlineSecurity   &lt;chr&gt; \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"…\n#&gt; $ OnlineBackup     &lt;chr&gt; \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"N…\n#&gt; $ DeviceProtection &lt;chr&gt; \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"Y…\n#&gt; $ TechSupport      &lt;chr&gt; \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"Yes…\n#&gt; $ StreamingTV      &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"Ye…\n#&gt; $ StreamingMovies  &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes…\n#&gt; $ Contract         &lt;chr&gt; \"Month-to-month\", \"One year\", \"Month-to-month\", \"One …\n#&gt; $ PaperlessBilling &lt;chr&gt; \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", …\n#&gt; $ PaymentMethod    &lt;chr&gt; \"Electronic check\", \"Mailed check\", \"Mailed check\", \"…\n#&gt; $ MonthlyCharges   &lt;dbl&gt; 29.85, 56.95, 53.85, 42.30, 70.70, 99.65, 89.10, 29.7…\n#&gt; $ TotalCharges     &lt;dbl&gt; 29.85, 1889.50, 108.15, 1840.75, 151.65, 820.50, 1949…\n#&gt; $ Churn            &lt;chr&gt; \"No\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"No\", \"Y…\n\n\n\nchurn_data_tbl &lt;- churn_data_raw %&gt;%\n                  select(Churn, everything(), -customerID) %&gt;%\n                  tidyr::drop_na()\n\n\n# Split test/training sets\nset.seed(100)\ntrain_test_split &lt;- rsample::initial_split(churn_data_tbl, prop =0.8)\ntrain_test_split\n\n#&gt; &lt;Training/Testing/Total&gt;\n#&gt; &lt;5625/1407/7032&gt;\n\n## &lt;Analysis/Assess/Total&gt;\n## &lt;5626/1406/7032&gt;\n\n# Retrieve train and test sets\ntrain_tbl &lt;- training(train_test_split)\ntest_tbl  &lt;- testing(train_test_split)\n\n\nchurn_data_tbl %&gt;% ggplot(aes(x = tenure)) + \n                     geom_histogram(binwidth = 0.5, fill =  \"#2DC6D6\") +\n                     labs(\n                       title = \"Tenure Counts Without Binning\",\n                       x     = \"tenure (month)\"\n                       )\n\n\n\n\n\n\n\n\n\nchurn_data_tbl %&gt;% ggplot(aes(x = tenure)) + \n  geom_histogram(bins = 6, color = \"white\", fill =  \"black\") +\n  labs(\n    title = \"Tenure Counts With Six Bins\",\n    x     = \"tenure (month)\"\n  )\n\n\n\n\n\n\n\n\n\nchurn_data_tbl %&gt;% ggplot(aes(x = TotalCharges)) + \n                     geom_histogram(bins = 100, fill =  \"blue\") +\n                     labs(\n                       title = \"TotalCharges Histogram, 100 bins\",\n                       x     = \"TotalCharges\"\n                       )\n\n\n\n\n\n\n\n\n\nchurn_data_tbl_mod &lt;- churn_data_tbl %&gt;% \n  mutate(TotalCharges = log10(TotalCharges))\nchurn_data_tbl_mod %&gt;% ggplot(aes(x = TotalCharges)) + \n                     geom_histogram(bins = 100, fill =  \"red\") +\n                     labs(\n                       title = \"TotalCharges Histogram, 100 bins\",\n                       x     = \"TotalCharges\"\n                       )\n\n\n\n\n\n\n\n\n\n# Determine if log transformation improves correlation \n# between TotalCharges and Churn\n\ntrain_tbl %&gt;%\n    select(Churn, TotalCharges) %&gt;%\n    mutate(\n        Churn = Churn %&gt;% as.factor() %&gt;% as.numeric(),\n        LogTotalCharges = log(TotalCharges)\n        ) %&gt;%\n    correlate() %&gt;%\n    focus(Churn) %&gt;%\n    fashion()\n\n\n  \n\n\n\n\nchurn_data_tbl %&gt;% \n        pivot_longer(cols      = c(Contract, InternetService, MultipleLines, PaymentMethod), \n                     names_to  = \"feature\", \n                     values_to = \"category\") %&gt;% \n        ggplot(aes(category)) +\n          geom_bar(fill = \"#2DC6D6\") +\n          facet_wrap(~ feature, scales = \"free\") +\n          labs(\n            title = \"Features with multiple categories: Need to be one-hot encoded\"\n          ) +\n          theme(axis.text.x = element_text(angle = 25, \n                                           hjust = 1))\n\n\n\n\n\n\n\n\n\n# Create recipe\nrec_obj &lt;- recipe(Churn ~ ., data = train_tbl) %&gt;%\n    step_rm(Churn) %&gt;% \n    step_discretize(tenure, options = list(cuts = 6)) %&gt;%\n    step_log(TotalCharges) %&gt;%\n    step_dummy(all_nominal(), -all_outcomes(), one_hot = T) %&gt;%\n    step_center(all_predictors(), -all_outcomes()) %&gt;%\n    step_scale(all_predictors(), -all_outcomes()) %&gt;%\n    prep(data = train_tbl)\n\n\nx_train_tbl &lt;- bake( rec_obj , new_data =  train_tbl)\nx_test_tbl  &lt;- bake( rec_obj , new_data =  test_tbl)\n\n\ny_train_vec &lt;- ifelse( train_tbl$Churn == \"Yes\", TRUE, FALSE )\ny_test_vec  &lt;- ifelse( test_tbl$Churn  == \"Yes\", TRUE, FALSE)\n\n\n# # Building our Artificial Neural Network\n\n#model_keras &lt;- keras_model_sequential()\n#\n#model_keras %&gt;% \n #   # First hidden layer\n#    layer_dense(\n#       units              = 16, \n#        kernel_initializer = \"uniform\", \n#        activation         = \"relu\",\n#        input_shape        = ncol(x_train_tbl))%&gt;% \n#    # Dropout to prevent overfitting\n#    layer_dropout(rate = 0.1) %&gt;%\n  #  # Second hidden layer\n#    layer_dense(\n#       units              = 16, \n#        kernel_initializer = \"uniform\", \n#        activation         = \"relu\") %&gt;% \n  #  # Dropout to prevent overfitting\n#    layer_dropout(rate = 0.1) %&gt;%\n  #  # Output layer\n#    layer_dense(\n#        units              = 1, \n#        kernel_initializer = \"uniform\", \n#        activation         = \"sigmoid\") %&gt;% \n #   # Compile ANN\n#   compile(\n#        optimizer = 'adam',\n#        loss      = 'binary_crossentropy',\n#        metrics   = c('accuracy')\n#    )\n#model_keras\n\nI have this error, that I shared in attermost. I tried to do the rest of the code but I do not know if they are accurate or not. I commented the code out in order to make it readable.\n\n# x_train_mrx = as.matrix(x_train_tbl)\n# \n# ncol(x_train_tbl)\n# \n# fit_keras &lt;- keras::fit(\n#     object = model_keras,\n#     x = x_train_tbl, \n#     y = y_train_vec , \n#     epochs = 35 , \n#     batch_size = 50 ,\n#     validation_split = 0.3 \n#     )\n# \n# fit_keras\n# \n# plot(fit_keras) +\n#  labs(title = \"Deep Learning Training Results\") +\n#   theme(legend.position  = \"bottom\", \n#         strip.placement  = \"inside\",\n#         strip.background = element_rect(fill = \"#grey\"))\n# \n## # Predicted Class\n# yhat_keras_class_vec &lt;- predict_classes(object = model_keras, x = #as.matrix(x_test_tbl)) %&gt;%\n#    as.vector()\n# \n# # Predicted Class Probability\n#as.matrix(x_test_tbl)) %&gt;%\n#     as.vector()\n# \n# # Format test data and predictions for yardstick metrics\n# estimates_keras_tbl &lt;- tibble(\n#     truth      = as.factor(y_test_vec) %&gt;% fct_recode(yes = \"1\", no = #\"0\"),\n#     estimate   = as.factor(yhat_keras_class_vec) %&gt;% fct_recode(yes = #\"1\", no = \"0\"),\n#    class_prob = yhat_keras_prob_vec\n# )\n# \n#estimates_keras_tbl\n# \n# # Confusion Table\n# estimates_keras_tbl %&gt;% conf_mat(\n#   truth,\n#   estimate)\n#\n# # Accuracy\n# estimates_keras_tbl %&gt;% accuracy(truth, estimate)\n# \n# # AUC\n# estimates_keras_tbl %&gt;% roc_auc(\n#   data,\n#   truth,\n#   event_level = \"second\")\n# \n# # Precision\n# tibble(\n#     precision = precision(\n#                         data,\n#                         truth),\n#     recall    = recall(\n#                       data,\n#                       truth)\n# )\n# \n# # F1-Statistic\n# estimates_keras_tbl %&gt;% f_meas(truth, estimate, beta = 1)\n# \n# class(model_keras)\n# \n# # Setup lime::model_type() function for keras\n# model_type.keras.engine.sequential.Sequential  &lt;- function(x, ...) {\n#     return(\"classification\")\n# }\n# \n# # Setup lime::predict_model() function for keras\n# predict_model.keras.engine.sequential.Sequential &lt;- function(x, newdata, #type, ...) {\n#     pred &lt;- predict_proba(object = x, x = as.matrix(newdata))\n#     return(data.frame(Yes = pred, No = 1 - pred))\n# }\n# \n# library(lime)\n# # Test our predict_model() function\n# predict_model(x = model_keras, newdata = x_test_tbl, type = 'raw') %&gt;%\n#     tibble::as_tibble()\n# \n# # Run lime() on training set\n# explainer &lt;- lime::lime(\n#     x_train_tbl, \n#     y_train_vec , \n#     bin_continuous = FALSE)\n# \n# explanation &lt;- lime::explain(\n#     x_test_tbl[1:10,], \n#     explainer = explainer, \n#     n_labels   = 1, \n#     n_features = 51,\n#     kernel_width   = 1)\n# \n# # Feature correlations to Churn\n# corrr_analysis &lt;- x_train_tbl %&gt;%\n#     mutate(Churn = y_train_vec) %&gt;%\n#     correlate() %&gt;%\n#     focus(Churn) %&gt;%\n#     rename(feature = rowname) %&gt;%\n#     arrange(abs(Churn)) %&gt;%\n#     mutate(feature = as_factor(feature)) \n# corrr_analysis\n# \n# # Correlation visualization\n# corrr_analysis %&gt;%\n#   ggplot(aes(x = ..., y = fct_reorder(..., desc(...)))) +\n#   geom_point() +\n#   \n#   # Positive Correlations - Contribute to churn\n#  geom_segment(aes(xend = ..., yend = ...), \n#               color = \"red\", \n#               data = corrr_analysis %&gt;% filter(... &gt; ...)) +\n#   geom_point(color = \"red\", \n#              data = corrr_analysis %&gt;% filter(... &gt; ...)) +\n#   \n#   # Negative Correlations - Prevent churn\n#  geom_segment(aes(xend = 0, yend = feature), \n#               color = \"#2DC6D6\", \n#                data = ...) +\n#   geom_point(color = \"#2DC6D6\", \n#              data = ...) +\n#   \n#   # Vertical lines\n#   geom_vline(xintercept = 0, color = \"#f1fa8c\", size = 1, linetype = 2) +\n#   geom_vline( ... ) +\n#   geom_vline( ... ) +\n#   \n#   # Aesthetics\n#   labs( ... )"
  }
]